[38;5;6mkafka [38;5;5m00:57:46.64 [0m[38;5;2mINFO [0m ==> 
[38;5;6mkafka [38;5;5m00:57:46.64 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami kafka container[0m
[38;5;6mkafka [38;5;5m00:57:46.65 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[38;5;6mkafka [38;5;5m00:57:46.65 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
[38;5;6mkafka [38;5;5m00:57:46.65 [0m[38;5;2mINFO [0m ==> 
[38;5;6mkafka [38;5;5m00:57:46.65 [0m[38;5;2mINFO [0m ==> ** Starting Kafka setup **
[38;5;6mkafka [38;5;5m00:57:46.85 [0m[38;5;2mINFO [0m ==> Initializing KRaft storage metadata
[38;5;6mkafka [38;5;5m00:57:46.86 [0m[38;5;2mINFO [0m ==> Adding KRaft SCRAM users at storage bootstrap
[38;5;6mkafka [38;5;5m00:57:46.93 [0m[38;5;2mINFO [0m ==> Formatting storage directories to add metadata...
All of the log directories are already formatted.

[38;5;6mkafka [38;5;5m00:57:55.13 [0m[38;5;2mINFO [0m ==> ** Kafka setup finished! **
[38;5;6mkafka [38;5;5m00:57:55.16 [0m[38;5;2mINFO [0m ==> ** Starting Kafka **
[2024-04-06 00:57:59,051] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2024-04-06 00:58:00,741] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2024-04-06 00:58:02,029] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2024-04-06 00:58:02,038] INFO [BrokerServer id=100] Transition from SHUTDOWN to STARTING (kafka.server.BrokerServer)
[2024-04-06 00:58:02,040] INFO [SharedServer id=100] Starting SharedServer (kafka.server.SharedServer)
[2024-04-06 00:58:02,533] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Recovering unflushed segment 0. 0/1 recovered for __cluster_metadata-0. (kafka.log.LogLoader)
[2024-04-06 00:58:02,537] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:02,538] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 0 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:02,546] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000192570.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-04-06 00:58:02,546] INFO Deleted producer state snapshot /bitnami/kafka/data/__cluster_metadata-0/00000000000000193271.snapshot (org.apache.kafka.storage.internals.log.SnapshotFile)
[2024-04-06 00:58:02,546] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 0 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:06,734] INFO [ProducerStateManager partition=__cluster_metadata-0]Wrote producer snapshot at offset 193271 with 0 producer ids in 5 ms. (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-04-06 00:58:06,836] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Loading producer state till offset 193271 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:06,836] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 193271 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:06,836] INFO [ProducerStateManager partition=__cluster_metadata-0]Loading producer state from snapshot file 'SnapshotFile(offset=193271, file=/bitnami/kafka/data/__cluster_metadata-0/00000000000000193271.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-04-06 00:58:06,839] INFO [LogLoader partition=__cluster_metadata-0, dir=/bitnami/kafka/data] Producer state recovery took 3ms for snapshot load and 0ms for segment recovery from offset 193271 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:07,043] INFO Initialized snapshots with IDs Set(OffsetAndEpoch(offset=9445, epoch=5), OffsetAndEpoch(offset=16696, epoch=11), OffsetAndEpoch(offset=23894, epoch=11), OffsetAndEpoch(offset=31092, epoch=11), OffsetAndEpoch(offset=38290, epoch=11), OffsetAndEpoch(offset=45488, epoch=11), OffsetAndEpoch(offset=52686, epoch=11), OffsetAndEpoch(offset=59884, epoch=11), OffsetAndEpoch(offset=67082, epoch=11), OffsetAndEpoch(offset=74280, epoch=11), OffsetAndEpoch(offset=81478, epoch=11), OffsetAndEpoch(offset=88676, epoch=11), OffsetAndEpoch(offset=95874, epoch=11), OffsetAndEpoch(offset=103071, epoch=11), OffsetAndEpoch(offset=110269, epoch=11), OffsetAndEpoch(offset=117467, epoch=11), OffsetAndEpoch(offset=124665, epoch=11), OffsetAndEpoch(offset=131863, epoch=11), OffsetAndEpoch(offset=139061, epoch=11), OffsetAndEpoch(offset=146258, epoch=11), OffsetAndEpoch(offset=153456, epoch=11), OffsetAndEpoch(offset=160654, epoch=11), OffsetAndEpoch(offset=167852, epoch=11), OffsetAndEpoch(offset=175050, epoch=11), OffsetAndEpoch(offset=182249, epoch=11)) from /bitnami/kafka/data/__cluster_metadata-0 (kafka.raft.KafkaMetadataLog$)
[2024-04-06 00:58:07,438] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2024-04-06 00:58:07,549] INFO [raft-expiration-reaper]: Starting (kafka.raft.TimingWheelExpirationService$ExpiredOperationReaper)
[2024-04-06 00:58:08,258] INFO [RaftManager id=100] Completed transition to FollowerState(fetchTimeoutMs=2000, epoch=12, leaderId=1, voters=[0, 1], highWatermark=Optional.empty, fetchingSnapshot=Optional.empty) from null (org.apache.kafka.raft.QuorumState)
[2024-04-06 00:58:08,334] INFO [kafka-100-raft-outbound-request-thread]: Starting (kafka.raft.RaftSendThread)
[2024-04-06 00:58:08,334] INFO [kafka-100-raft-io-thread]: Starting (kafka.raft.KafkaRaftManager$RaftIoThread)
[2024-04-06 00:58:08,446] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:08,530] INFO [BrokerServer id=100] Starting broker (kafka.server.BrokerServer)
[2024-04-06 00:58:08,629] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:08,641] INFO [broker-100-ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-04-06 00:58:08,642] INFO [broker-100-ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-04-06 00:58:08,643] INFO [broker-100-ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-04-06 00:58:08,730] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:08,730] INFO [broker-100-ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2024-04-06 00:58:08,830] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:08,931] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:08,945] INFO [BrokerServer id=100] Waiting for controller quorum voters future (kafka.server.BrokerServer)
[2024-04-06 00:58:08,945] INFO [BrokerServer id=100] Finished waiting for controller quorum voters future (kafka.server.BrokerServer)
[2024-04-06 00:58:09,031] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,041] INFO [broker-100-to-controller-forwarding-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:09,129] INFO [broker-100-to-controller-forwarding-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:09,132] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,232] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,333] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,433] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,458] INFO [RaftManager id=100] Registered the listener org.apache.kafka.image.loader.MetadataLoader@261586666 (org.apache.kafka.raft.KafkaRaftClient)
[2024-04-06 00:58:09,534] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,634] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,737] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,838] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:09,939] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,039] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,140] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,240] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,429] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,530] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,631] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,732] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,833] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,934] INFO [MetadataLoader id=100] initializeNewPublishers: the loader is still catching up because we still don't know the high water mark yet. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:10,938] INFO [RaftManager id=100] High watermark set to Optional[LogOffsetMetadata(offset=193331, metadata=Optional.empty)] for the first time for epoch 12 (org.apache.kafka.raft.FollowerState)
[2024-04-06 00:58:11,034] INFO [MetadataLoader id=100] handleLoadSnapshot(00000000000000182249-0000000011): incrementing HandleLoadSnapshotCount to 1. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:11,334] INFO [MetadataLoader id=100] handleLoadSnapshot(00000000000000182249-0000000011): generated a metadata delta between offset -1 and this snapshot in 298859 us. (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:11,337] INFO [MetadataLoader id=100] maybePublishMetadata(SNAPSHOT): The loader is still catching up because we have loaded up to offset 182248, but the high water mark is 193332 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:11,338] INFO [MetadataLoader id=100] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 182248, but the high water mark is 193332 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:12,133] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-04-06 00:58:12,429] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2024-04-06 00:58:12,433] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2024-04-06 00:58:12,536] INFO [SocketServer listenerType=BROKER, nodeId=100] Created data-plane acceptor and processors for endpoint : ListenerName(CLIENT) (kafka.network.SocketServer)
[2024-04-06 00:58:12,538] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2024-04-06 00:58:12,541] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2024-04-06 00:58:12,629] INFO Successfully logged in. (org.apache.kafka.common.security.authenticator.AbstractLogin)
[2024-04-06 00:58:12,730] INFO [SocketServer listenerType=BROKER, nodeId=100] Created data-plane acceptor and processors for endpoint : ListenerName(INTERNAL) (kafka.network.SocketServer)
[2024-04-06 00:58:12,832] INFO [broker-100-to-controller-alter-partition-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:12,832] INFO [broker-100-to-controller-alter-partition-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:13,156] INFO [MetadataLoader id=100] maybePublishMetadata(LOG_DELTA): The loader is still catching up because we have loaded up to offset 193330, but the high water mark is 193335 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:13,157] INFO [MetadataLoader id=100] initializeNewPublishers: The loader is still catching up because we have loaded up to offset 193330, but the high water mark is 193335 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:13,158] INFO [MetadataLoader id=100] maybePublishMetadata(LOG_DELTA): The loader finished catching up to the current high water mark of 193335 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:13,235] INFO [ExpirationReaper-100-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,238] INFO [ExpirationReaper-100-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,240] INFO [ExpirationReaper-100-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,242] INFO [ExpirationReaper-100-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,329] INFO [ExpirationReaper-100-RemoteFetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,335] INFO [MetadataLoader id=100] InitializeNewPublishers: initializing SnapshotGenerator with a snapshot at offset 193334 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:13,435] INFO [ExpirationReaper-100-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,436] INFO [ExpirationReaper-100-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,732] INFO [BrokerLifecycleManager id=100] Incarnation mhcCn_iBQeOUDlVtns7H_Q of broker 100 in cluster znEutl8A5RzhVHrrrZUG3g is now STARTING. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:13,733] INFO [broker-100-to-controller-heartbeat-channel-manager]: Starting (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:13,733] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 00:58:13,831] INFO [BrokerLifecycleManager id=100] Successfully registered broker 100 with broker epoch 193337 (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:13,936] INFO [ExpirationReaper-100-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2024-04-06 00:58:13,941] INFO [BrokerLifecycleManager id=100] The broker has caught up. Transitioning from STARTING to RECOVERY. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:14,032] INFO [BrokerLifecycleManager id=100] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:14,137] INFO [BrokerServer id=100] Waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2024-04-06 00:58:14,137] INFO [MetadataLoader id=100] InitializeNewPublishers: initializing BrokerMetadataPublisher with a snapshot at offset 193337 (org.apache.kafka.image.loader.MetadataLoader)
[2024-04-06 00:58:14,138] INFO [BrokerServer id=100] Finished waiting for the broker metadata publishers to be installed (kafka.server.BrokerServer)
[2024-04-06 00:58:14,138] INFO [BrokerServer id=100] Waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2024-04-06 00:58:14,138] INFO [BrokerServer id=100] Finished waiting for the controller to acknowledge that we are caught up (kafka.server.BrokerServer)
[2024-04-06 00:58:14,138] INFO [BrokerServer id=100] Waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2024-04-06 00:58:14,139] INFO [BrokerMetadataPublisher id=100] Publishing initial metadata at offset OffsetAndEpoch(offset=193337, epoch=12) with metadata.version 3.6-IV2. (kafka.server.metadata.BrokerMetadataPublisher)
[2024-04-06 00:58:14,146] INFO Loading logs from log dirs ArrayBuffer(/bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,239] INFO Skipping recovery of 38 logs from /bitnami/kafka/data since clean shutdown file was found (kafka.log.LogManager)
[2024-04-06 00:58:14,429] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Loading producer state till offset 12 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,429] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 12 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,429] INFO [ProducerStateManager partition=__consumer_offsets-2]Loading producer state from snapshot file 'SnapshotFile(offset=12, file=/bitnami/kafka/data/__consumer_offsets-2/00000000000000000012.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-04-06 00:58:14,431] INFO [LogLoader partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Producer state recovery took 2ms for snapshot load and 0ms for segment recovery from offset 12 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,437] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-2, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=12) with 1 segments, local-log-start-offset 0 and log-end-offset 12 in 103ms (1/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,445] INFO [LogLoader partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,530] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-38, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 92ms (2/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,541] INFO [LogLoader partition=aggregator.traces-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,545] INFO Completed load of Log(dir=/bitnami/kafka/data/aggregator.traces-0, topicId=N4cRvHiKSA6ycNHWiVYb5A, topic=aggregator.traces, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 15ms (3/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,549] INFO [LogLoader partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,629] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-47, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 84ms (4/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,634] INFO [LogLoader partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,637] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-16, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (5/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,642] INFO [LogLoader partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,645] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-30, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (6/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,733] INFO [LogLoader partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,736] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-39, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 91ms (7/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,741] INFO [LogLoader partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,744] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-13, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (8/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,833] INFO [LogLoader partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,838] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-31, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 94ms (9/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,846] INFO [LogLoader partition=ingestion.logs-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,852] INFO Completed load of Log(dir=/bitnami/kafka/data/ingestion.logs-1, topicId=hlx5EftcTMe2-opCgnStUQ, topic=ingestion.logs, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (10/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,939] INFO [LogLoader partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,942] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-4, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 89ms (11/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:14,947] INFO [LogLoader partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:14,950] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-6, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 8ms (12/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,036] INFO [LogLoader partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,040] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-32, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 89ms (13/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,045] INFO [LogLoader partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,048] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-29, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (14/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,052] INFO [LogLoader partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,130] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-24, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 82ms (15/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,141] INFO [LogLoader partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,146] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-42, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 16ms (16/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,152] INFO [LogLoader partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,231] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-23, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 84ms (17/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,245] INFO [LogLoader partition=ingestion.metrics-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,248] INFO Completed load of Log(dir=/bitnami/kafka/data/ingestion.metrics-0, topicId=MJvkOKIfSfitCb-7_9GyQA, topic=ingestion.metrics, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 17ms (18/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,340] INFO [LogLoader partition=monitornotifications-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,343] INFO Completed load of Log(dir=/bitnami/kafka/data/monitornotifications-0, topicId=oMm9lBwLQrGC4CJxe51XcA, topic=monitornotifications, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 95ms (19/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,347] INFO [LogLoader partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,350] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-25, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (20/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,354] INFO [LogLoader partition=metadata.ingest.stats-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,356] INFO Completed load of Log(dir=/bitnami/kafka/data/metadata.ingest.stats-0, topicId=Fhj_NBEDS6O3D-rvdfB6rg, topic=metadata.ingest.stats, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (21/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,439] INFO [LogLoader partition=eval_global_aggregation-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,442] INFO Completed load of Log(dir=/bitnami/kafka/data/eval_global_aggregation-0, topicId=Nn7tXOYpTFe2hXwm9RMy8A, topic=eval_global_aggregation, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 85ms (22/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,446] INFO [LogLoader partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,448] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-40, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (23/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,544] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Loading producer state till offset 11 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,544] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 11 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,544] INFO [ProducerStateManager partition=__consumer_offsets-14]Loading producer state from snapshot file 'SnapshotFile(offset=11, file=/bitnami/kafka/data/__consumer_offsets-14/00000000000000000011.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-04-06 00:58:15,545] INFO [LogLoader partition=__consumer_offsets-14, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 11 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,547] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-14, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=11) with 1 segments, local-log-start-offset 0 and log-end-offset 11 in 98ms (24/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,551] INFO [LogLoader partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,553] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-7, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (25/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,633] INFO [LogLoader partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,636] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-20, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 82ms (26/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,645] INFO [LogLoader partition=metadata.ingest.stats-1, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,648] INFO Completed load of Log(dir=/bitnami/kafka/data/metadata.ingest.stats-1, topicId=Fhj_NBEDS6O3D-rvdfB6rg, topic=metadata.ingest.stats, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (27/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,659] INFO [LogLoader partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,661] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-49, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (28/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,736] INFO [LogLoader partition=metadata.rollup.compactions-0, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,739] INFO Completed load of Log(dir=/bitnami/kafka/data/metadata.rollup.compactions-0, topicId=ZFtp0aF4Q52jZYgVwYe6oA, topic=metadata.rollup.compactions, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 78ms (29/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,748] INFO [LogLoader partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,750] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-18, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 11ms (30/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,837] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Loading producer state till offset 12 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,838] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Reloading from producer snapshot and rebuilding producer state from offset 12 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,838] INFO [ProducerStateManager partition=__consumer_offsets-48]Loading producer state from snapshot file 'SnapshotFile(offset=12, file=/bitnami/kafka/data/__consumer_offsets-48/00000000000000000012.snapshot)' (org.apache.kafka.storage.internals.log.ProducerStateManager)
[2024-04-06 00:58:15,839] INFO [LogLoader partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 12 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,841] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-48, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=12) with 1 segments, local-log-start-offset 0 and log-end-offset 12 in 91ms (31/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,845] INFO [LogLoader partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,848] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-17, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (32/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,857] INFO [LogLoader partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,931] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-8, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 83ms (33/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,940] INFO [LogLoader partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,943] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-26, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 12ms (34/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:15,948] INFO [LogLoader partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:15,950] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-12, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 6ms (35/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:16,033] INFO [LogLoader partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:16,035] INFO [BrokerLifecycleManager id=100] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:16,036] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-41, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 7ms (36/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:16,039] INFO [LogLoader partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:16,041] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-3, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 5ms (37/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:16,049] INFO [LogLoader partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2024-04-06 00:58:16,130] INFO Completed load of Log(dir=/bitnami/kafka/data/__consumer_offsets-35, topicId=bMQvYuPsTuWoGw93TAK53w, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments, local-log-start-offset 0 and log-end-offset 0 in 89ms (38/38 completed in /bitnami/kafka/data) (kafka.log.LogManager)
[2024-04-06 00:58:16,134] INFO Loaded 38 logs in 1988ms (kafka.log.LogManager)
[2024-04-06 00:58:16,135] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2024-04-06 00:58:16,136] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2024-04-06 00:58:16,233] INFO Starting the log cleaner (kafka.log.LogCleaner)
[2024-04-06 00:58:16,736] INFO [kafka-log-cleaner-thread-0]: Starting (kafka.log.LogCleaner$CleanerThread)
[2024-04-06 00:58:16,741] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2024-04-06 00:58:16,743] INFO [GroupCoordinator 100]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:16,745] INFO [AddPartitionsToTxnSenderThread-100]: Starting (kafka.server.AddPartitionsToTxnManager)
[2024-04-06 00:58:16,747] INFO [GroupCoordinator 100]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:16,748] INFO [TransactionCoordinator id=100] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-04-06 00:58:16,831] INFO [TransactionCoordinator id=100] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2024-04-06 00:58:16,832] INFO [TxnMarkerSenderThread-100]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2024-04-06 00:58:16,832] INFO [BrokerMetadataPublisher id=100] Updating metadata.version to 14 at offset OffsetAndEpoch(offset=193337, epoch=12). (kafka.server.metadata.BrokerMetadataPublisher)
[2024-04-06 00:58:16,837] INFO [Broker id=100] Transitioning 38 partition(s) to local followers. (state.change.logger)
[2024-04-06 00:58:16,934] INFO [Broker id=100] Creating new partition __consumer_offsets-48 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,146] INFO [Partition __consumer_offsets-48 broker=100] Log loaded for partition __consumer_offsets-48 with initial high watermark 12 (kafka.cluster.Partition)
[2024-04-06 00:58:17,149] INFO [Broker id=100] Follower __consumer_offsets-48 starts at leader epoch 2 from offset 12 with partition epoch 8 and high watermark 12. Current leader is 0. Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 00:58:17,149] INFO [Broker id=100] Creating new partition ingestion.metrics-0 with topic id MJvkOKIfSfitCb-7_9GyQA. (state.change.logger)
[2024-04-06 00:58:17,229] INFO [Partition ingestion.metrics-0 broker=100] Log loaded for partition ingestion.metrics-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,230] INFO [Broker id=100] Follower ingestion.metrics-0 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,230] INFO [Broker id=100] Creating new partition __consumer_offsets-13 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,232] INFO [Partition __consumer_offsets-13 broker=100] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,233] INFO [Broker id=100] Follower __consumer_offsets-13 starts at leader epoch 0 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,233] INFO [Broker id=100] Creating new partition __consumer_offsets-42 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,234] INFO [Partition __consumer_offsets-42 broker=100] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,234] INFO [Broker id=100] Follower __consumer_offsets-42 starts at leader epoch 5 from offset 0 with partition epoch 11 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,235] INFO [Broker id=100] Creating new partition __consumer_offsets-23 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,236] INFO [Partition __consumer_offsets-23 broker=100] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,236] INFO [Broker id=100] Follower __consumer_offsets-23 starts at leader epoch 4 from offset 0 with partition epoch 13 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 4. (state.change.logger)
[2024-04-06 00:58:17,236] INFO [Broker id=100] Creating new partition ingestion.logs-1 with topic id hlx5EftcTMe2-opCgnStUQ. (state.change.logger)
[2024-04-06 00:58:17,237] INFO [Partition ingestion.logs-1 broker=100] Log loaded for partition ingestion.logs-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,238] INFO [Broker id=100] Follower ingestion.logs-1 starts at leader epoch 0 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,238] INFO [Broker id=100] Creating new partition __consumer_offsets-17 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,239] INFO [Partition __consumer_offsets-17 broker=100] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,239] INFO [Broker id=100] Follower __consumer_offsets-17 starts at leader epoch 2 from offset 0 with partition epoch 8 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 00:58:17,240] INFO [Broker id=100] Creating new partition __consumer_offsets-32 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,241] INFO [Partition __consumer_offsets-32 broker=100] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,241] INFO [Broker id=100] Follower __consumer_offsets-32 starts at leader epoch 5 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,241] INFO [Broker id=100] Creating new partition metadata.ingest.stats-1 with topic id Fhj_NBEDS6O3D-rvdfB6rg. (state.change.logger)
[2024-04-06 00:58:17,242] INFO [Partition metadata.ingest.stats-1 broker=100] Log loaded for partition metadata.ingest.stats-1 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,243] INFO [Broker id=100] Follower metadata.ingest.stats-1 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,243] INFO [Broker id=100] Creating new partition metadata.rollup.compactions-0 with topic id ZFtp0aF4Q52jZYgVwYe6oA. (state.change.logger)
[2024-04-06 00:58:17,244] INFO [Partition metadata.rollup.compactions-0 broker=100] Log loaded for partition metadata.rollup.compactions-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,244] INFO [Broker id=100] Follower metadata.rollup.compactions-0 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,244] INFO [Broker id=100] Creating new partition __consumer_offsets-30 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,245] INFO [Partition __consumer_offsets-30 broker=100] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,246] INFO [Broker id=100] Follower __consumer_offsets-30 starts at leader epoch 0 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,246] INFO [Broker id=100] Creating new partition __consumer_offsets-26 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,247] INFO [Partition __consumer_offsets-26 broker=100] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,247] INFO [Broker id=100] Follower __consumer_offsets-26 starts at leader epoch 6 from offset 0 with partition epoch 13 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 6. (state.change.logger)
[2024-04-06 00:58:17,247] INFO [Broker id=100] Creating new partition __consumer_offsets-7 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,248] INFO [Partition __consumer_offsets-7 broker=100] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,248] INFO [Broker id=100] Follower __consumer_offsets-7 starts at leader epoch 0 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,249] INFO [Broker id=100] Creating new partition __consumer_offsets-40 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,250] INFO [Partition __consumer_offsets-40 broker=100] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,250] INFO [Broker id=100] Follower __consumer_offsets-40 starts at leader epoch 0 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,250] INFO [Broker id=100] Creating new partition __consumer_offsets-38 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,251] INFO [Partition __consumer_offsets-38 broker=100] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,251] INFO [Broker id=100] Follower __consumer_offsets-38 starts at leader epoch 0 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,251] INFO [Broker id=100] Creating new partition __consumer_offsets-3 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,330] INFO [Partition __consumer_offsets-3 broker=100] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,330] INFO [Broker id=100] Follower __consumer_offsets-3 starts at leader epoch 0 from offset 0 with partition epoch 5 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,330] INFO [Broker id=100] Creating new partition __consumer_offsets-47 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,331] INFO [Partition __consumer_offsets-47 broker=100] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,332] INFO [Broker id=100] Follower __consumer_offsets-47 starts at leader epoch 4 from offset 0 with partition epoch 13 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 4. (state.change.logger)
[2024-04-06 00:58:17,332] INFO [Broker id=100] Creating new partition __consumer_offsets-16 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,333] INFO [Partition __consumer_offsets-16 broker=100] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,333] INFO [Broker id=100] Follower __consumer_offsets-16 starts at leader epoch 0 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,334] INFO [Broker id=100] Creating new partition eval_global_aggregation-0 with topic id Nn7tXOYpTFe2hXwm9RMy8A. (state.change.logger)
[2024-04-06 00:58:17,335] INFO [Partition eval_global_aggregation-0 broker=100] Log loaded for partition eval_global_aggregation-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,335] INFO [Broker id=100] Follower eval_global_aggregation-0 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,335] INFO [Broker id=100] Creating new partition __consumer_offsets-14 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,336] INFO [Partition __consumer_offsets-14 broker=100] Log loaded for partition __consumer_offsets-14 with initial high watermark 11 (kafka.cluster.Partition)
[2024-04-06 00:58:17,336] INFO [Broker id=100] Follower __consumer_offsets-14 starts at leader epoch 5 from offset 11 with partition epoch 13 and high watermark 11. Current leader is 102. Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,336] INFO [Broker id=100] Creating new partition __consumer_offsets-12 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,337] INFO [Partition __consumer_offsets-12 broker=100] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,337] INFO [Broker id=100] Follower __consumer_offsets-12 starts at leader epoch 0 from offset 0 with partition epoch 5 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,337] INFO [Broker id=100] Creating new partition __consumer_offsets-41 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,338] INFO [Partition __consumer_offsets-41 broker=100] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,338] INFO [Broker id=100] Follower __consumer_offsets-41 starts at leader epoch 2 from offset 0 with partition epoch 12 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 00:58:17,339] INFO [Broker id=100] Creating new partition __consumer_offsets-24 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,340] INFO [Partition __consumer_offsets-24 broker=100] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,340] INFO [Broker id=100] Follower __consumer_offsets-24 starts at leader epoch 2 from offset 0 with partition epoch 8 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 00:58:17,340] INFO [Broker id=100] Creating new partition __consumer_offsets-20 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,341] INFO [Partition __consumer_offsets-20 broker=100] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,341] INFO [Broker id=100] Follower __consumer_offsets-20 starts at leader epoch 5 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,342] INFO [Broker id=100] Creating new partition __consumer_offsets-49 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,343] INFO [Partition __consumer_offsets-49 broker=100] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,343] INFO [Broker id=100] Follower __consumer_offsets-49 starts at leader epoch 5 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,343] INFO [Broker id=100] Creating new partition __consumer_offsets-18 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,344] INFO [Partition __consumer_offsets-18 broker=100] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,344] INFO [Broker id=100] Follower __consumer_offsets-18 starts at leader epoch 5 from offset 0 with partition epoch 11 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,344] INFO [Broker id=100] Creating new partition __consumer_offsets-31 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,345] INFO [Partition __consumer_offsets-31 broker=100] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,345] INFO [Broker id=100] Follower __consumer_offsets-31 starts at leader epoch 4 from offset 0 with partition epoch 11 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 4. (state.change.logger)
[2024-04-06 00:58:17,346] INFO [Broker id=100] Creating new partition metadata.ingest.stats-0 with topic id Fhj_NBEDS6O3D-rvdfB6rg. (state.change.logger)
[2024-04-06 00:58:17,346] INFO [Partition metadata.ingest.stats-0 broker=100] Log loaded for partition metadata.ingest.stats-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,346] INFO [Broker id=100] Follower metadata.ingest.stats-0 starts at leader epoch 0 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,347] INFO [Broker id=100] Creating new partition __consumer_offsets-29 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,348] INFO [Partition __consumer_offsets-29 broker=100] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,348] INFO [Broker id=100] Follower __consumer_offsets-29 starts at leader epoch 0 from offset 0 with partition epoch 5 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,348] INFO [Broker id=100] Creating new partition monitornotifications-0 with topic id oMm9lBwLQrGC4CJxe51XcA. (state.change.logger)
[2024-04-06 00:58:17,349] INFO [Partition monitornotifications-0 broker=100] Log loaded for partition monitornotifications-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,349] INFO [Broker id=100] Follower monitornotifications-0 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,349] INFO [Broker id=100] Creating new partition __consumer_offsets-25 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,430] INFO [Partition __consumer_offsets-25 broker=100] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,431] INFO [Broker id=100] Follower __consumer_offsets-25 starts at leader epoch 0 from offset 0 with partition epoch 7 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,431] INFO [Broker id=100] Creating new partition __consumer_offsets-39 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,432] INFO [Partition __consumer_offsets-39 broker=100] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,433] INFO [Broker id=100] Follower __consumer_offsets-39 starts at leader epoch 4 from offset 0 with partition epoch 13 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 4. (state.change.logger)
[2024-04-06 00:58:17,433] INFO [Broker id=100] Creating new partition __consumer_offsets-8 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,433] INFO [Partition __consumer_offsets-8 broker=100] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,433] INFO [Broker id=100] Follower __consumer_offsets-8 starts at leader epoch 5 from offset 0 with partition epoch 13 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,434] INFO [Broker id=100] Creating new partition __consumer_offsets-6 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,434] INFO [Partition __consumer_offsets-6 broker=100] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,434] INFO [Broker id=100] Follower __consumer_offsets-6 starts at leader epoch 0 from offset 0 with partition epoch 5 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 0. (state.change.logger)
[2024-04-06 00:58:17,435] INFO [Broker id=100] Creating new partition __consumer_offsets-35 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,435] INFO [Partition __consumer_offsets-35 broker=100] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,435] INFO [Broker id=100] Follower __consumer_offsets-35 starts at leader epoch 6 from offset 0 with partition epoch 9 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 6. (state.change.logger)
[2024-04-06 00:58:17,436] INFO [Broker id=100] Creating new partition __consumer_offsets-4 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,436] INFO [Partition __consumer_offsets-4 broker=100] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,436] INFO [Broker id=100] Follower __consumer_offsets-4 starts at leader epoch 5 from offset 0 with partition epoch 11 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 00:58:17,437] INFO [Broker id=100] Creating new partition aggregator.traces-0 with topic id N4cRvHiKSA6ycNHWiVYb5A. (state.change.logger)
[2024-04-06 00:58:17,437] INFO [Partition aggregator.traces-0 broker=100] Log loaded for partition aggregator.traces-0 with initial high watermark 0 (kafka.cluster.Partition)
[2024-04-06 00:58:17,437] INFO [Broker id=100] Follower aggregator.traces-0 starts at leader epoch 7 from offset 0 with partition epoch 10 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 00:58:17,438] INFO [Broker id=100] Creating new partition __consumer_offsets-2 with topic id bMQvYuPsTuWoGw93TAK53w. (state.change.logger)
[2024-04-06 00:58:17,438] INFO [Partition __consumer_offsets-2 broker=100] Log loaded for partition __consumer_offsets-2 with initial high watermark 12 (kafka.cluster.Partition)
[2024-04-06 00:58:17,438] INFO [Broker id=100] Follower __consumer_offsets-2 starts at leader epoch 2 from offset 12 with partition epoch 8 and high watermark 12. Current leader is 0. Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 00:58:17,441] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-38, __consumer_offsets-49, metadata.rollup.compactions-0, __consumer_offsets-16, __consumer_offsets-8, __consumer_offsets-2, __consumer_offsets-13, __consumer_offsets-35, __consumer_offsets-24, monitornotifications-0, ingestion.metrics-0, __consumer_offsets-32, __consumer_offsets-48, __consumer_offsets-29, __consumer_offsets-18, __consumer_offsets-40, __consumer_offsets-7, __consumer_offsets-23, __consumer_offsets-4, __consumer_offsets-26, __consumer_offsets-42, __consumer_offsets-31, metadata.ingest.stats-1, __consumer_offsets-20, __consumer_offsets-12, __consumer_offsets-6, __consumer_offsets-17, __consumer_offsets-39, eval_global_aggregation-0, __consumer_offsets-47, __consumer_offsets-25, __consumer_offsets-3, __consumer_offsets-14, __consumer_offsets-30, __consumer_offsets-41, metadata.ingest.stats-0, ingestion.logs-1, aggregator.traces-0) (kafka.server.ReplicaFetcherManager)
[2024-04-06 00:58:17,441] INFO [Broker id=100] Stopped fetchers as part of become-follower for 38 partitions (state.change.logger)
[2024-04-06 00:58:17,546] INFO [ReplicaFetcherThread-0-101]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,551] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 101 for partitions Map(__consumer_offsets-49 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), __consumer_offsets-38 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),0,0), metadata.rollup.compactions-0 -> InitialFetchState(Some(ZFtp0aF4Q52jZYgVwYe6oA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0), __consumer_offsets-13 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),0,0), ingestion.metrics-0 -> InitialFetchState(Some(MJvkOKIfSfitCb-7_9GyQA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0), monitornotifications-0 -> InitialFetchState(Some(oMm9lBwLQrGC4CJxe51XcA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0), __consumer_offsets-32 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), __consumer_offsets-18 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), __consumer_offsets-7 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-4 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), metadata.ingest.stats-1 -> InitialFetchState(Some(Fhj_NBEDS6O3D-rvdfB6rg),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0), __consumer_offsets-20 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), eval_global_aggregation-0 -> InitialFetchState(Some(Nn7tXOYpTFe2hXwm9RMy8A),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0), __consumer_offsets-25 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),0,0), aggregator.traces-0 -> InitialFetchState(Some(N4cRvHiKSA6ycNHWiVYb5A),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),7,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 00:58:17,634] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition aggregator.traces-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,636] INFO [UnifiedLog partition=aggregator.traces-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,636] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 1 for partitions Map(__consumer_offsets-16 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-40 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-29 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-12 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-6 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-3 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), ingestion.logs-1 -> InitialFetchState(Some(hlx5EftcTMe2-opCgnStUQ),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), metadata.ingest.stats-0 -> InitialFetchState(Some(Fhj_NBEDS6O3D-rvdfB6rg),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0), __consumer_offsets-30 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 00:58:17,637] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,638] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition ingestion.logs-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,639] INFO [UnifiedLog partition=ingestion.logs-1, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,639] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition metadata.ingest.stats-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,729] INFO [UnifiedLog partition=metadata.ingest.stats-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,638] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition ingestion.metrics-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,730] INFO [UnifiedLog partition=ingestion.metrics-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,730] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition monitornotifications-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,730] INFO [UnifiedLog partition=monitornotifications-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,731] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-32 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,731] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-30 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,731] INFO [UnifiedLog partition=__consumer_offsets-30, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,731] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 102 for partitions Map(__consumer_offsets-8 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), __consumer_offsets-23 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),4,0), __consumer_offsets-31 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),4,0), __consumer_offsets-42 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,0), __consumer_offsets-39 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),4,0), __consumer_offsets-14 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),5,11), __consumer_offsets-47 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),4,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 00:58:17,732] INFO [UnifiedLog partition=__consumer_offsets-32, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,732] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,732] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,732] INFO [UnifiedLog partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,733] INFO [UnifiedLog partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,733] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-16 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,733] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition metadata.ingest.stats-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,733] INFO [UnifiedLog partition=__consumer_offsets-16, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,733] INFO [UnifiedLog partition=metadata.ingest.stats-1, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,734] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-18 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,734] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,734] INFO [UnifiedLog partition=__consumer_offsets-18, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,734] INFO [UnifiedLog partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,735] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,735] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-12 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,735] INFO [UnifiedLog partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,735] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,736] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-40 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,736] INFO [UnifiedLog partition=__consumer_offsets-40, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,736] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition metadata.rollup.compactions-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,737] INFO [UnifiedLog partition=metadata.rollup.compactions-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,737] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,737] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,738] INFO [UnifiedLog partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,738] INFO [UnifiedLog partition=__consumer_offsets-4, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,741] INFO [ReplicaFetcherThread-0-102]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,741] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-49 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,741] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-39 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,741] INFO [UnifiedLog partition=__consumer_offsets-49, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,742] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,742] INFO [UnifiedLog partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,742] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition eval_global_aggregation-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,742] INFO [UnifiedLog partition=eval_global_aggregation-0, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,743] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-20 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,743] INFO [UnifiedLog partition=__consumer_offsets-20, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,743] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,743] INFO [UnifiedLog partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,829] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 0 for partitions Map(__consumer_offsets-35 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),6,0), __consumer_offsets-24 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),2,0), __consumer_offsets-2 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),2,12), __consumer_offsets-48 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),2,12), __consumer_offsets-26 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),6,0), __consumer_offsets-17 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),2,0), __consumer_offsets-41 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),2,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 00:58:17,741] INFO [UnifiedLog partition=__consumer_offsets-39, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,830] INFO [Broker id=100] Started fetchers as part of become-follower for 38 partitions (state.change.logger)
[2024-04-06 00:58:17,831] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-23 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,831] INFO [UnifiedLog partition=__consumer_offsets-23, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,831] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-8 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,831] INFO [UnifiedLog partition=__consumer_offsets-8, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,831] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-47 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,832] INFO [UnifiedLog partition=__consumer_offsets-47, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,832] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,832] INFO [UnifiedLog partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,832] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-42 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,832] INFO [UnifiedLog partition=__consumer_offsets-42, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,830] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,833] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-41 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,833] INFO [UnifiedLog partition=__consumer_offsets-41, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,833] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-17 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,834] INFO [UnifiedLog partition=__consumer_offsets-17, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,834] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-26 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,834] INFO [UnifiedLog partition=__consumer_offsets-26, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,834] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-35 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,834] INFO [UnifiedLog partition=__consumer_offsets-35, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:17,834] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-24 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 00:58:17,835] INFO [UnifiedLog partition=__consumer_offsets-24, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 00:58:18,037] INFO [BrokerLifecycleManager id=100] The broker is in RECOVERY. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:18,230] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,232] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,233] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,233] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,234] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,234] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,234] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,235] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,235] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,235] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,236] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,236] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,237] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,237] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,237] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,237] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[6] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,238] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,238] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,239] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[6]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,240] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,240] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,240] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,240] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,240] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,240] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,240] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,240] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,241] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,241] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,242] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,242] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,242] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,242] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,242] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,242] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,242] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,243] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,243] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,243] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,244] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,244] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,244] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,244] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,244] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,244] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,329] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,330] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,331] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,331] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,331] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,332] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,332] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,333] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,333] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,333] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,334] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,334] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,334] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,335] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,335] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,336] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,336] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,336] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,337] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,337] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,337] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,338] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,338] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,339] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,339] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[6] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,339] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,340] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[6]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,340] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,340] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,341] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,341] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,341] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,342] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,435] INFO [DynamicConfigPublisher broker id=100] Updating topic aggregator.traces with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,442] INFO [DynamicConfigPublisher broker id=100] Updating topic metadata.index.appends with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,444] INFO [DynamicConfigPublisher broker id=100] Updating topic metadata.ingest.stats with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,445] INFO [DynamicConfigPublisher broker id=100] Updating topic aggregator.logs with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,446] INFO [DynamicConfigPublisher broker id=100] Updating topic aggregator.metrics with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,531] INFO [DynamicConfigPublisher broker id=100] Updating topic aggregator.pass.through with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,532] INFO [DynamicConfigPublisher broker id=100] Updating topic ingestion.logs with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,533] INFO [DynamicConfigPublisher broker id=100] Updating topic ingestion.metrics with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,535] INFO [DynamicConfigPublisher broker id=100] Updating topic monitornotifications with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,536] INFO [DynamicConfigPublisher broker id=100] Updating topic __consumer_offsets with new configuration : cleanup.policy -> compact,segment.bytes -> 104857600,compression.type -> producer (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,537] INFO [DynamicConfigPublisher broker id=100] Updating topic ingestion.traces with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,538] INFO [DynamicConfigPublisher broker id=100] Updating topic metadata.rollup.compactions with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,539] INFO [DynamicConfigPublisher broker id=100] Updating topic eval_global_aggregation with new configuration : retention.ms -> 7200000 (kafka.server.metadata.DynamicConfigPublisher)
[2024-04-06 00:58:18,631] INFO [BrokerServer id=100] Finished waiting for the initial broker metadata update to be published (kafka.server.BrokerServer)
[2024-04-06 00:58:18,633] INFO KafkaConfig values: 
	advertised.listeners = CLIENT://kafka-kraft-broker-0.kafka-kraft-broker-headless.default.svc.cluster.local:9092,INTERNAL://kafka-kraft-broker-0.kafka-kraft-broker-headless.default.svc.cluster.local:9094
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.include.jmx.reporter = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 100
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = CONTROLLER
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = [0@kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9093, 1@kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093]
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	early.start.listeners = null
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.consumer.assignors = [org.apache.kafka.coordinator.group.assignor.RangeAssignor]
	group.consumer.heartbeat.interval.ms = 5000
	group.consumer.max.heartbeat.interval.ms = 15000
	group.consumer.max.session.timeout.ms = 60000
	group.consumer.max.size = 2147483647
	group.consumer.min.heartbeat.interval.ms = 5000
	group.consumer.min.session.timeout.ms = 45000
	group.consumer.session.timeout.ms = 45000
	group.coordinator.new.enable = false
	group.coordinator.threads = 1
	group.initial.rebalance.delay.ms = 3000
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = INTERNAL
	inter.broker.protocol.version = 3.6-IV2
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = CLIENT:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
	listeners = CLIENT://:9092,INTERNAL://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /bitnami/kafka/data
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.local.retention.bytes = -2
	log.local.retention.ms = -2
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.after.max.ms = 9223372036854775807
	log.message.timestamp.before.max.ms = 9223372036854775807
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.max.snapshot.interval.ms = 3600000
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.idle.interval.ms = 500
	metadata.max.retention.bytes = 104857600
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 100
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = [broker]
	producer.id.expiration.check.interval.ms = 600000
	producer.id.expiration.ms = 86400000
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.custom.metadata.max.bytes = 128
	remote.log.metadata.manager.class.name = org.apache.kafka.server.log.remote.metadata.storage.TopicBasedRemoteLogMetadataManager
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = rlmm.config.
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = rsm.config.
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [PLAIN, SCRAM-SHA-256, SCRAM-SHA-512]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = PLAIN
	sasl.mechanism.inter.broker.protocol = PLAIN
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	sasl.server.max.receive.size = 524288
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	server.max.startup.time.ms = 9223372036854775807
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.listen.backlog.size = 50
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.partition.verification.enable = true
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	unstable.api.versions.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = null
	zookeeper.connection.timeout.ms = null
	zookeeper.max.in.flight.requests = 10
	zookeeper.metadata.migration.enable = false
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
 (kafka.server.KafkaConfig)
[2024-04-06 00:58:18,730] INFO [BrokerLifecycleManager id=100] The broker has been unfenced. Transitioning from RECOVERY to RUNNING. (kafka.server.BrokerLifecycleManager)
[2024-04-06 00:58:18,731] INFO [BrokerServer id=100] Waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2024-04-06 00:58:18,733] INFO [BrokerServer id=100] Finished waiting for the broker to be unfenced (kafka.server.BrokerServer)
[2024-04-06 00:58:18,740] INFO authorizerStart completed for endpoint CLIENT. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2024-04-06 00:58:18,740] INFO authorizerStart completed for endpoint INTERNAL. Endpoint is now READY. (org.apache.kafka.server.network.EndpointReadyFutures)
[2024-04-06 00:58:18,741] INFO [SocketServer listenerType=BROKER, nodeId=100] Enabling request processing. (kafka.network.SocketServer)
[2024-04-06 00:58:18,832] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.DataPlaneAcceptor)
[2024-04-06 00:58:18,835] INFO [Broker id=100] Transitioning 9 partition(s) to local followers. (state.change.logger)
[2024-04-06 00:58:18,837] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.DataPlaneAcceptor)
[2024-04-06 00:58:18,838] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-16 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 0, 100], partitionEpoch=8, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,839] INFO [Broker id=100] Skipped the become-follower state change for metadata.ingest.stats-0 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) and partition state LeaderAndIsrPartitionState(topicName='metadata.ingest.stats', partitionIndex=0, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 100], partitionEpoch=8, replicas=[1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,840] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-29 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 101, 100], partitionEpoch=6, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,841] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-30 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 102, 100], partitionEpoch=10, replicas=[1, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,931] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-12 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 101, 100], partitionEpoch=6, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,931] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-40 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 0, 100], partitionEpoch=8, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,932] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-6 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 101, 100], partitionEpoch=6, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,932] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-3 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 101, 100], partitionEpoch=6, replicas=[1, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,932] INFO [Broker id=100] Skipped the become-follower state change for ingestion.logs-1 with topic id Some(hlx5EftcTMe2-opCgnStUQ) and partition state LeaderAndIsrPartitionState(topicName='ingestion.logs', partitionIndex=1, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 100], partitionEpoch=8, replicas=[1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:18,933] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,933] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,934] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,934] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,934] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,934] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,934] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,934] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,934] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,934] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,935] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,935] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,935] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:18,935] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,936] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,937] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,938] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,938] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,939] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,939] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,940] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:18,937] INFO [Broker id=100] Transitioning 7 partition(s) to local followers. (state.change.logger)
[2024-04-06 00:58:18,940] INFO [BrokerServer id=100] Waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2024-04-06 00:58:18,941] INFO [BrokerServer id=100] Finished waiting for all of the authorizer futures to be completed (kafka.server.BrokerServer)
[2024-04-06 00:58:18,941] INFO [BrokerServer id=100] Waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2024-04-06 00:58:18,942] INFO [BrokerServer id=100] Finished waiting for all of the SocketServer Acceptors to be started (kafka.server.BrokerServer)
[2024-04-06 00:58:18,942] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-47 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 0, 100], partitionEpoch=14, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 00:58:18,943] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-31 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[101, 102, 100], partitionEpoch=12, replicas=[102, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 00:58:18,944] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=-1, leader=102, leaderEpoch=5, isr=[102, 0, 100], partitionEpoch=14, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:18,944] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-42 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=-1, leader=102, leaderEpoch=5, isr=[101, 102, 100], partitionEpoch=12, replicas=[100, 102, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,029] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-23 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 0, 100], partitionEpoch=14, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 00:58:19,030] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-39 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 0, 100], partitionEpoch=14, replicas=[102, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 00:58:19,030] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=-1, leader=102, leaderEpoch=5, isr=[102, 0, 100], partitionEpoch=14, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:18,942] INFO [BrokerServer id=100] Transition from STARTING to STARTED (kafka.server.BrokerServer)
[2024-04-06 00:58:19,030] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,034] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,035] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,035] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,035] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,035] INFO Kafka version: 3.6.1 (org.apache.kafka.common.utils.AppInfoParser)
[2024-04-06 00:58:19,035] INFO Kafka commitId: 5e3c2b738d253ff5 (org.apache.kafka.common.utils.AppInfoParser)
[2024-04-06 00:58:19,035] INFO Kafka startTimeMs: 1712365099034 (org.apache.kafka.common.utils.AppInfoParser)
[2024-04-06 00:58:19,038] INFO [KafkaRaftServer nodeId=100] Kafka Server started (kafka.server.KafkaRaftServer)
[2024-04-06 00:58:19,041] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,041] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,041] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,041] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,051] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,430] INFO [Broker id=100] Transitioning 2 partition(s) to local followers. (state.change.logger)
[2024-04-06 00:58:19,431] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-49 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=-1, leader=101, leaderEpoch=5, isr=[101, 1, 100], partitionEpoch=8, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,432] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-2 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=-1, leader=0, leaderEpoch=2, isr=[1, 0, 100], partitionEpoch=9, replicas=[0, 1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 2. (state.change.logger)
[2024-04-06 00:58:19,432] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,432] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,432] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,432] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,433] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,433] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,435] INFO [Broker id=100] Transitioning 20 partition(s) to local followers. (state.change.logger)
[2024-04-06 00:58:19,436] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-48 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=-1, leader=0, leaderEpoch=2, isr=[101, 0, 100], partitionEpoch=9, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 2. (state.change.logger)
[2024-04-06 00:58:19,436] INFO [Broker id=100] Skipped the become-follower state change for ingestion.metrics-0 with topic id Some(MJvkOKIfSfitCb-7_9GyQA) and partition state LeaderAndIsrPartitionState(topicName='ingestion.metrics', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,437] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-13 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=-1, leader=101, leaderEpoch=0, isr=[101, 102, 100], partitionEpoch=10, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:19,438] INFO [Broker id=100] Skipped the become-follower state change for eval_global_aggregation-0 with topic id Some(Nn7tXOYpTFe2hXwm9RMy8A) and partition state LeaderAndIsrPartitionState(topicName='eval_global_aggregation', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,439] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-41 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=-1, leader=0, leaderEpoch=2, isr=[102, 0, 100], partitionEpoch=13, replicas=[0, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 2. (state.change.logger)
[2024-04-06 00:58:19,439] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-24 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=-1, leader=0, leaderEpoch=2, isr=[101, 0, 100], partitionEpoch=9, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 2. (state.change.logger)
[2024-04-06 00:58:19,440] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-20 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=-1, leader=101, leaderEpoch=5, isr=[101, 1, 100], partitionEpoch=8, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,440] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-17 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=-1, leader=0, leaderEpoch=2, isr=[101, 0, 100], partitionEpoch=9, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 2. (state.change.logger)
[2024-04-06 00:58:19,441] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-18 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=-1, leader=101, leaderEpoch=5, isr=[101, 102, 100], partitionEpoch=12, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,442] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=-1, leader=101, leaderEpoch=5, isr=[101, 0, 100], partitionEpoch=10, replicas=[100, 101, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,442] INFO [Broker id=100] Skipped the become-follower state change for metadata.ingest.stats-1 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) and partition state LeaderAndIsrPartitionState(topicName='metadata.ingest.stats', partitionIndex=1, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,443] INFO [Broker id=100] Skipped the become-follower state change for metadata.rollup.compactions-0 with topic id Some(ZFtp0aF4Q52jZYgVwYe6oA) and partition state LeaderAndIsrPartitionState(topicName='metadata.rollup.compactions', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,443] INFO [Broker id=100] Skipped the become-follower state change for monitornotifications-0 with topic id Some(oMm9lBwLQrGC4CJxe51XcA) and partition state LeaderAndIsrPartitionState(topicName='monitornotifications', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,444] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-25 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=-1, leader=101, leaderEpoch=0, isr=[101, 0, 100], partitionEpoch=8, replicas=[101, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:19,445] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=-1, leader=0, leaderEpoch=6, isr=[102, 0, 100], partitionEpoch=14, replicas=[100, 0, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 6. (state.change.logger)
[2024-04-06 00:58:19,445] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-7 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=-1, leader=101, leaderEpoch=0, isr=[101, 102, 100], partitionEpoch=10, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:19,445] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-38 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=-1, leader=101, leaderEpoch=0, isr=[101, 102, 100], partitionEpoch=10, replicas=[101, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 00:58:19,446] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=-1, leader=0, leaderEpoch=6, isr=[1, 0, 100], partitionEpoch=10, replicas=[100, 0, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 6. (state.change.logger)
[2024-04-06 00:58:19,446] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-4 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=-1, leader=101, leaderEpoch=5, isr=[101, 102, 100], partitionEpoch=12, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 5. (state.change.logger)
[2024-04-06 00:58:19,446] INFO [Broker id=100] Skipped the become-follower state change for aggregator.traces-0 with topic id Some(N4cRvHiKSA6ycNHWiVYb5A) and partition state LeaderAndIsrPartitionState(topicName='aggregator.traces', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=7, isr=[101, 100], partitionEpoch=11, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 7. (state.change.logger)
[2024-04-06 00:58:19,447] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,448] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,449] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,449] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,449] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,450] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,450] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,450] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,450] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,450] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,451] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[2] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,451] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,451] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[2]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,451] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,451] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,451] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,451] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,452] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,452] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,452] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,452] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,452] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[6] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[6]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,453] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,454] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[6] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,454] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,454] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[6]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,529] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[5] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 00:58:19,529] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 00:58:19,530] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[5]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:38,629] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-49 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,630] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Partition __consumer_offsets-35 has an older epoch (6) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,629] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-8 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,635] WARN [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Partition __consumer_offsets-35 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,636] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Partition __consumer_offsets-26 has an older epoch (6) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,637] WARN [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Partition __consumer_offsets-26 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,636] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-8 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,636] INFO [Broker id=100] Transitioning 16 partition(s) to local leaders. (state.change.logger)
[2024-04-06 01:02:38,639] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-42 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,640] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-42 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,641] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-14 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,641] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-14 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,637] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-49 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,641] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-32 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-32 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-18 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-18 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-4 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-4 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,642] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-20 has an older epoch (5) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,732] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-20 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,732] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition metadata.rollup.compactions-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,733] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition metadata.rollup.compactions-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,734] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition ingestion.metrics-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,736] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition ingestion.metrics-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,738] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition monitornotifications-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,739] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition monitornotifications-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,739] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition metadata.ingest.stats-1 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,739] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition metadata.ingest.stats-1 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,739] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition eval_global_aggregation-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,740] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition eval_global_aggregation-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,740] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition aggregator.traces-0 has an older epoch (7) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,740] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition aggregator.traces-0 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 01:02:38,832] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(ingestion.metrics-0, eval_global_aggregation-0, __consumer_offsets-14, __consumer_offsets-42, __consumer_offsets-20, __consumer_offsets-49, __consumer_offsets-18, __consumer_offsets-32, metadata.ingest.stats-1, metadata.rollup.compactions-0, monitornotifications-0, __consumer_offsets-26, __consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-4, aggregator.traces-0) (kafka.server.ReplicaFetcherManager)
[2024-04-06 01:02:38,939] INFO [Broker id=100] Leader ingestion.metrics-0 with topic id Some(MJvkOKIfSfitCb-7_9GyQA) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,032] INFO [Broker id=100] Leader eval_global_aggregation-0 with topic id Some(Nn7tXOYpTFe2hXwm9RMy8A) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,038] INFO [Broker id=100] Leader __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 11 with partition epoch 15, high watermark 11, ISR [102,0,100], adding replicas [] and removing replicas [] . Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,043] INFO [Broker id=100] Leader __consumer_offsets-42 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 13, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,130] INFO [Broker id=100] Leader __consumer_offsets-20 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 9, high watermark 0, ISR [101,1,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,135] INFO [Broker id=100] Leader __consumer_offsets-49 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 9, high watermark 0, ISR [101,1,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,141] INFO [Broker id=100] Leader __consumer_offsets-18 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 13, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,147] INFO [Broker id=100] Leader __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 11, high watermark 0, ISR [101,0,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,234] INFO [Broker id=100] Leader metadata.ingest.stats-1 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,239] INFO [Broker id=100] Leader metadata.rollup.compactions-0 with topic id Some(ZFtp0aF4Q52jZYgVwYe6oA) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,244] INFO [Broker id=100] Leader monitornotifications-0 with topic id Some(oMm9lBwLQrGC4CJxe51XcA) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,250] INFO [Broker id=100] Leader __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 7 from offset 0 with partition epoch 15, high watermark 0, ISR [102,0,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 6. (state.change.logger)
[2024-04-06 01:02:39,256] INFO [Broker id=100] Leader __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 15, high watermark 0, ISR [102,0,100], adding replicas [] and removing replicas [] . Previous leader Some(102) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,333] INFO [Broker id=100] Leader __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 7 from offset 0 with partition epoch 11, high watermark 0, ISR [1,0,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 6. (state.change.logger)
[2024-04-06 01:02:39,338] INFO [Broker id=100] Leader __consumer_offsets-4 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 6 from offset 0 with partition epoch 13, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 5. (state.change.logger)
[2024-04-06 01:02:39,343] INFO [Broker id=100] Leader aggregator.traces-0 with topic id Some(N4cRvHiKSA6ycNHWiVYb5A) starts at leader epoch 8 from offset 0 with partition epoch 12, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 7. (state.change.logger)
[2024-04-06 01:02:39,434] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 32 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,435] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,436] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 14 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,436] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,436] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 26 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 42 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 8 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 35 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 20 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 4 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,437] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 18 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,437] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,445] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-32 in 8 milliseconds for epoch 6, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,642] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-abcba8f0-f249-47c3-80e0-9d24c8abf48a, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.134, clientHost=/10.43.128.134, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,730] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-5800ec0b-877c-44f0-967d-7c452e136b3c, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.136, clientHost=/10.43.128.136, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,732] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-cc551c06-87dd-4ea0-abf0-4c460030495e, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.137, clientHost=/10.43.128.137, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,732] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-e9a25728-88f8-4313-90d8-0417d1875693, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.139, clientHost=/10.43.128.139, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,733] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-0c986f24-7201-4ce2-a1b2-fcdb1d5f7b23, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,734] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-cd7f4ef7-0a1f-4be1-8257-0a8ec5385a10, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 01:02:39,738] INFO [GroupCoordinator 100]: Loading group metadata for metadata.ingest.stats.consumer with generation 7 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 01:02:39,745] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-14 in 309 milliseconds for epoch 6, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,748] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-26 in 311 milliseconds for epoch 7, of which 311 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,750] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-42 in 313 milliseconds for epoch 6, of which 312 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,751] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-8 in 314 milliseconds for epoch 6, of which 314 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,752] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-35 in 315 milliseconds for epoch 7, of which 315 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,753] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-20 in 316 milliseconds for epoch 6, of which 316 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,754] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-4 in 317 milliseconds for epoch 6, of which 317 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,755] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-49 in 318 milliseconds for epoch 6, of which 317 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:02:39,756] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-18 in 319 milliseconds for epoch 6, of which 319 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 01:58:13,579] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000200589-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 01:58:13,729] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000200589-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 02:01:37,910] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-cd7f4ef7-0a1f-4be1-8257-0a8ec5385a10 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:01:37,923] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 7 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-cd7f4ef7-0a1f-4be1-8257-0a8ec5385a10 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:01:37,926] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 8 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:02:09,946] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:02:09,947] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 8 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:02:12,952] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 9 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:02:13,045] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114 for group metadata.ingest.stats.consumer for generation 9. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 02:58:14,028] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000207788-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 02:58:14,041] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000207788-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 03:58:14,515] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000214986-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 03:58:14,527] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000214986-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 04:58:14,613] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000222183-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 04:58:14,621] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000222183-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 04:59:49,940] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 04:59:49,941] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 9 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 04:59:49,941] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 10 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 05:01:12,452] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 05:01:12,453] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 10 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 05:01:15,454] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 11 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 05:01:15,549] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7 for group metadata.ingest.stats.consumer for generation 11. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 05:58:14,752] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000229381-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 05:58:14,761] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000229381-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 06:58:15,035] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000236579-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 06:58:15,045] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000236579-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 07:58:15,243] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000243777-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 07:58:15,252] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000243777-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 08:58:15,655] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000250975-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 08:58:15,662] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000250975-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 09:58:15,691] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000258172-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 09:58:15,699] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000258172-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 10:58:15,917] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000265369-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 10:58:15,929] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000265369-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 11:58:16,194] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000272567-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 11:58:16,206] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000272567-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 12:58:16,692] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000279765-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 12:58:16,699] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000279765-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 13:58:16,944] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000286963-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 13:58:16,953] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000286963-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 14:58:17,218] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000294161-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 14:58:17,224] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000294161-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 15:58:17,602] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000301359-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 15:58:17,612] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000301359-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 16:58:18,016] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000308557-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 16:58:18,024] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000308557-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 17:58:18,442] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000315755-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 17:58:18,452] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000315755-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 18:45:49,646] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:45:49,649] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 11 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:45:49,650] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 12 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:46:30,254] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:46:30,256] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 12 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:46:33,260] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 13 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:46:33,349] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794 for group metadata.ingest.stats.consumer for generation 13. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 18:58:18,448] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000322952-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 18:58:18,457] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000322952-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 19:58:18,884] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000330150-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 19:58:18,892] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000330150-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 20:58:19,172] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000337348-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 20:58:19,178] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000337348-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 21:22:32,069] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:22:32,070] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 13 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:22:32,070] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 14 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:23:32,741] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:23:32,742] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 14 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:23:35,743] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 15 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:23:35,780] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2 for group metadata.ingest.stats.consumer for generation 15. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 21:58:19,525] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000344546-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 21:58:19,533] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000344546-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 22:24:05,027] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:05,028] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 15 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:05,028] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 16 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:49,842] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:49,842] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 16 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:52,843] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 17 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:24:52,945] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8 for group metadata.ingest.stats.consumer for generation 17. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:31:59,367] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:31:59,368] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 17 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:31:59,368] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 18 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:34:44,441] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:34:44,442] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 18 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:34:47,443] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 19 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:34:47,562] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124 for group metadata.ingest.stats.consumer for generation 19. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:47:06,366] INFO [GroupCoordinator 100]: Member metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124 in group metadata.ingest.stats.consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:47:06,368] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 19 (__consumer_offsets-14) (reason: removing member metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:47:06,369] INFO [GroupCoordinator 100]: Group metadata.ingest.stats.consumer with generation 20 is now empty (__consumer_offsets-14) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:48:16,749] INFO [GroupMetadataManager brokerId=100] Group metadata.ingest.stats.consumer transitioned to Dead in generation 20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 22:49:22,842] INFO [GroupCoordinator 100]: Static member with groupInstanceId=metadata.ingest.stats.consumer-0 and unknown member id joins group metadata.ingest.stats.consumer in Empty state. Created a new member id metadata.ingest.stats.consumer-0-ae145ec9-744c-4b1c-b2a7-dcc9eba624a8 for this member and add to the group. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:49:22,842] INFO [GroupCoordinator 100]: Preparing to rebalance group metadata.ingest.stats.consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-14) (reason: Adding new member metadata.ingest.stats.consumer-0-ae145ec9-744c-4b1c-b2a7-dcc9eba624a8 with group instance id Some(metadata.ingest.stats.consumer-0); client reason: not provided) (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:49:25,843] INFO [GroupCoordinator 100]: Stabilized group metadata.ingest.stats.consumer generation 1 (__consumer_offsets-14) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:49:25,949] INFO [GroupCoordinator 100]: Assignment received from leader metadata.ingest.stats.consumer-0-ae145ec9-744c-4b1c-b2a7-dcc9eba624a8 for group metadata.ingest.stats.consumer for generation 1. The group has 1 members, 1 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 22:58:19,840] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000351744-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 22:58:19,853] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000351744-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-06 23:47:32,653] INFO [Broker id=100] Transitioning 9 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:47:32,661] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-32, __consumer_offsets-48, __consumer_offsets-14, __consumer_offsets-41, __consumer_offsets-26, __consumer_offsets-8, __consumer_offsets-24, __consumer_offsets-35, __consumer_offsets-17) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:47:32,666] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=-1, leader=100, leaderEpoch=6, isr=[101, 100], partitionEpoch=12, replicas=[100, 101, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 6. Current high watermark 0, ISR [101,100], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:47:32,666] INFO [Broker id=100] Leader __consumer_offsets-48 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 3 from offset 26 with partition epoch 10, high watermark 26, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 23:47:32,674] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=-1, leader=100, leaderEpoch=6, isr=[102, 100], partitionEpoch=16, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 6. Current high watermark 26, ISR [102,100], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:47:32,674] INFO [Broker id=100] Leader __consumer_offsets-41 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 3 from offset 0 with partition epoch 14, high watermark 0, ISR [102,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 23:47:32,680] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=-1, leader=100, leaderEpoch=7, isr=[102, 100], partitionEpoch=16, replicas=[100, 0, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 7. Current high watermark 0, ISR [102,100], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:47:32,680] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=-1, leader=100, leaderEpoch=6, isr=[102, 100], partitionEpoch=16, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 6. Current high watermark 0, ISR [102,100], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:47:32,680] INFO [Broker id=100] Leader __consumer_offsets-24 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 3 from offset 0 with partition epoch 10, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 23:47:32,685] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=-1, leader=100, leaderEpoch=7, isr=[1, 100], partitionEpoch=12, replicas=[100, 0, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 7. Current high watermark 0, ISR [1,100], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:47:32,685] INFO [Broker id=100] Leader __consumer_offsets-17 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 3 from offset 0 with partition epoch 10, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(0) and previous leader epoch was 2. (state.change.logger)
[2024-04-06 23:47:32,689] INFO [Broker id=100] Transitioning 7 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-47 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 100], partitionEpoch=15, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-16 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 100], partitionEpoch=9, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-25 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=-1, leader=101, leaderEpoch=0, isr=[101, 100], partitionEpoch=9, replicas=[101, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-23 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 100], partitionEpoch=15, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-39 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=-1, leader=102, leaderEpoch=4, isr=[102, 100], partitionEpoch=15, replicas=[102, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 4. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-40 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=-1, leader=1, leaderEpoch=0, isr=[1, 100], partitionEpoch=9, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 0. (state.change.logger)
[2024-04-06 23:47:32,690] INFO [Broker id=100] Follower __consumer_offsets-2 starts at leader epoch 3 from offset 26 with partition epoch 10 and high watermark 26. Current leader is 1. Previous leader Some(1) and previous leader epoch was 3. (state.change.logger)
[2024-04-06 23:47:32,691] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:47:32,691] INFO [Broker id=100] Stopped fetchers as part of become-follower for 1 partitions (state.change.logger)
[2024-04-06 23:47:32,695] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 1 for partitions Map(__consumer_offsets-2 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),3,26)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:47:32,695] INFO [Broker id=100] Started fetchers as part of become-follower for 1 partitions (state.change.logger)
[2024-04-06 23:47:32,730] INFO [ReplicaFetcherThread-0-0]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:47:32,733] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:32,760] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 163822 due to node 0 being disconnected (elapsed time since creation: 138ms, elapsed time since send: 138ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:32,830] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=467686532, epoch=163822) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.BrokerBlockingSender.sendRequest(BrokerBlockingSender.scala:113)
	at kafka.server.RemoteLeaderEndPoint.fetch(RemoteLeaderEndPoint.scala:79)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:316)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:130)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:129)
	at scala.Option.foreach(Option.scala:407)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:129)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:112)
	at kafka.server.ReplicaFetcherThread.doWork(ReplicaFetcherThread.scala:98)
	at org.apache.kafka.server.util.ShutdownableThread.run(ShutdownableThread.java:130)
[2024-04-06 23:47:32,929] INFO [ReplicaFetcherThread-0-0]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:47:32,931] INFO [ReplicaFetcherThread-0-0]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:47:33,034] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 32 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,034] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 48 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 14 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 41 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 26 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 8 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 24 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 35 in epoch 7 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,036] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,036] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 17 in epoch 3 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,037] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,037] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,037] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,038] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,038] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,038] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[4] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,038] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[0] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[3] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,237] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-3ee4a28c-f1f6-43fb-9f3e-fc6e4047d295, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.134, clientHost=/10.43.128.134, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,238] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-7286d7d0-af1b-4a56-86e6-4b847743119a, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.136, clientHost=/10.43.128.136, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,238] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-7cb98ac9-d094-4fa7-ae32-88f6a48fa4f6, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.137, clientHost=/10.43.128.137, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,239] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-b8d707e1-25c3-423b-b3e5-02f46de25bb6, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.139, clientHost=/10.43.128.139, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,239] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-b1489fdc-4d68-4150-81f6-71ce99bcb176, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,239] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-4531564a-0d1a-4948-828c-c09361d00022, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,240] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-23dec4f7-b6e4-415f-b27b-2edbb327b256, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.129.222, clientHost=/10.43.129.222, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,240] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-43324a95-5c0d-4977-9b35-61d3c41dd6b4, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.42, clientHost=/10.43.128.42, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,241] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-5e1abeb4-aac5-4698-bf45-8b2b7c0625b9, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.43, clientHost=/10.43.128.43, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,241] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-620a33f2-8405-43aa-9f24-012cf4a474d0, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.45, clientHost=/10.43.128.45, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 9. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,241] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-5583ca23-73d3-48c2-8785-0d60607d8461, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.46, clientHost=/10.43.128.46, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 11. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,242] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-92d862ee-b672-4bdc-b2bb-9b93cbe6cc35, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.47, clientHost=/10.43.128.47, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 13. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,242] INFO Loaded member MemberMetadata(memberId=metadata.index.appends.consumer-0-afc5c8cb-f28f-4447-a872-13d428fca647, groupInstanceId=Some(metadata.index.appends.consumer-0), clientId=10.43.128.48, clientHost=/10.43.128.48, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.index.appends.consumer with generation 15. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:47:33,243] INFO [GroupCoordinator 100]: Loading group metadata for metadata.index.appends.consumer with generation 15 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:47:33,243] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-48 in 207 milliseconds for epoch 3, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-41 in 208 milliseconds for epoch 3, of which 208 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-24 in 208 milliseconds for epoch 3, of which 208 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,244] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-17 in 208 milliseconds for epoch 3, of which 208 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[4]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[0]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:33,245] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[3]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:47:43,439] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:43,441] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41056 due to node 1 being disconnected (elapsed time since creation: 4505ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:43,441] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:47:43,442] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:47:48,059] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:48,059] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41057 due to node 1 being disconnected (elapsed time since creation: 4515ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:48,060] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:47:48,060] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:47:52,770] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:52,770] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41059 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:52,770] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:47:52,770] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:47:57,680] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:57,681] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41061 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:47:57,681] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:47:57,681] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:02,999] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:02,999] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41063 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:02,999] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:02,999] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:09,115] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:09,115] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41065 due to node 1 being disconnected (elapsed time since creation: 4510ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:09,115] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:09,116] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:16,845] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:16,846] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41067 due to node 1 being disconnected (elapsed time since creation: 4504ms, elapsed time since send: 4501ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:16,846] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:16,846] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:27,776] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:27,776] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41069 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:27,776] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:27,776] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:41,304] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:41,304] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41071 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:41,305] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:41,305] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:48:54,685] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:54,685] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41073 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:48:54,685] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:48:54,685] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:49:08,180] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:08,181] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41075 due to node 1 being disconnected (elapsed time since creation: 4506ms, elapsed time since send: 4503ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:08,181] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:49:08,181] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:49:21,681] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:21,681] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41077 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:21,681] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:49:21,681] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:49:35,111] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:35,111] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41079 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:35,111] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:49:35,111] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:49:48,653] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:48,653] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41081 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:49:48,653] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:49:48,654] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:50:02,147] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:02,147] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41083 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:02,148] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:50:02,148] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:50:15,615] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:15,616] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41085 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:15,616] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:50:15,616] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:50:29,080] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:29,080] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41087 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:29,080] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:50:29,080] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:50:42,513] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:42,513] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41089 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:42,513] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:50:42,513] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:50:56,185] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:56,186] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41091 due to node 1 being disconnected (elapsed time since creation: 4507ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:50:56,186] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:50:56,186] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:51:09,760] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:09,761] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41093 due to node 1 being disconnected (elapsed time since creation: 4506ms, elapsed time since send: 4501ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:09,761] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:51:09,761] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:51:23,301] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:23,301] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41095 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:23,301] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:51:23,301] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:51:36,747] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:36,748] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41097 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:36,748] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:51:36,748] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:51:50,400] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:50,400] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41099 due to node 1 being disconnected (elapsed time since creation: 4510ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:51:50,400] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:51:50,400] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:52:03,791] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:03,792] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41101 due to node 1 being disconnected (elapsed time since creation: 4510ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:03,792] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:52:03,792] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:52:17,357] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:17,358] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41103 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:17,358] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:52:17,358] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:52:30,971] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:30,972] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41105 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:30,972] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:52:30,972] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:52:44,371] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:44,371] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41107 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:44,371] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:52:44,371] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:52:58,036] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:58,037] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41109 due to node 1 being disconnected (elapsed time since creation: 4505ms, elapsed time since send: 4502ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:52:58,037] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:52:58,037] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:53:11,666] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:11,666] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41111 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:11,666] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:53:11,666] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:53:25,168] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:25,168] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41113 due to node 1 being disconnected (elapsed time since creation: 4507ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:25,168] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:53:25,168] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:53:38,534] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:38,534] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41115 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:38,535] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:53:38,535] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:53:52,078] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:52,078] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41117 due to node 1 being disconnected (elapsed time since creation: 4510ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:53:52,078] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:53:52,078] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:54:05,705] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:05,705] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41119 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4504ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:05,705] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:54:05,705] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:54:19,089] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:19,090] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41121 due to node 1 being disconnected (elapsed time since creation: 4509ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:19,090] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:54:19,090] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:54:32,759] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:32,759] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41123 due to node 1 being disconnected (elapsed time since creation: 4506ms, elapsed time since send: 4501ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:32,759] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:54:32,760] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:54:46,294] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Disconnecting from node 1 due to request timeout. (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:46,294] INFO [BrokerToControllerChannelManager id=100 name=heartbeat] Cancelled in-flight BROKER_HEARTBEAT request with correlation id 41125 due to node 1 being disconnected (elapsed time since creation: 4508ms, elapsed time since send: 4505ms, request timeout: 4500ms) (org.apache.kafka.clients.NetworkClient)
[2024-04-06 23:54:46,294] INFO [broker-100-to-controller-heartbeat-channel-manager]: Recorded new controller, from now on will use node kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9093 (id: 1 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2024-04-06 23:54:46,294] INFO [BrokerLifecycleManager id=100] Unable to send a heartbeat because the RPC got timed out before it could be sent. (kafka.server.BrokerLifecycleManager)
[2024-04-06 23:54:54,850] INFO [Broker id=100] Transitioning 38 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:54,851] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-23 has an older epoch (4) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-23 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-31 has an older epoch (4) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-31 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-39 has an older epoch (4) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-39 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-47 has an older epoch (4) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,852] WARN [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Partition __consumer_offsets-47 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-48 starts at leader epoch 63 from offset 26 with partition epoch 70 and high watermark 26. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower ingestion.metrics-0 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-13 starts at leader epoch 59 from offset 0 with partition epoch 71 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 59. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-42 starts at leader epoch 66 from offset 0 with partition epoch 74 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-23 starts at leader epoch 64 from offset 0 with partition epoch 75 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower ingestion.logs-1 starts at leader epoch 60 from offset 0 with partition epoch 68 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-17 starts at leader epoch 63 from offset 0 with partition epoch 70 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:54:54,853] INFO [Broker id=100] Follower __consumer_offsets-32 starts at leader epoch 66 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower metadata.ingest.stats-1 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower metadata.rollup.compactions-0 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower __consumer_offsets-30 starts at leader epoch 61 from offset 0 with partition epoch 71 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower __consumer_offsets-26 starts at leader epoch 66 from offset 0 with partition epoch 76 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower __consumer_offsets-7 starts at leader epoch 59 from offset 0 with partition epoch 71 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 59. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower __consumer_offsets-40 starts at leader epoch 60 from offset 0 with partition epoch 69 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,854] INFO [Broker id=100] Follower __consumer_offsets-38 starts at leader epoch 59 from offset 0 with partition epoch 71 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 59. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-3 starts at leader epoch 61 from offset 0 with partition epoch 67 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-47 starts at leader epoch 64 from offset 0 with partition epoch 75 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-16 starts at leader epoch 60 from offset 0 with partition epoch 69 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower eval_global_aggregation-0 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-14 starts at leader epoch 65 from offset 26 with partition epoch 76 and high watermark 26. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-12 starts at leader epoch 60 from offset 0 with partition epoch 67 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,855] INFO [Broker id=100] Follower __consumer_offsets-41 starts at leader epoch 62 from offset 0 with partition epoch 74 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:54:54,856] INFO [Broker id=100] Follower __consumer_offsets-24 starts at leader epoch 63 from offset 0 with partition epoch 70 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:54:54,856] INFO [Broker id=100] Follower __consumer_offsets-20 starts at leader epoch 66 from offset 0 with partition epoch 70 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,856] INFO [Broker id=100] Follower __consumer_offsets-49 starts at leader epoch 66 from offset 0 with partition epoch 70 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,856] INFO [Broker id=100] Follower __consumer_offsets-18 starts at leader epoch 66 from offset 0 with partition epoch 74 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,856] INFO [Broker id=100] Follower __consumer_offsets-31 starts at leader epoch 65 from offset 0 with partition epoch 73 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:54:54,857] INFO [Broker id=100] Follower metadata.ingest.stats-0 starts at leader epoch 60 from offset 0 with partition epoch 68 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,857] INFO [Broker id=100] Follower __consumer_offsets-29 starts at leader epoch 60 from offset 0 with partition epoch 67 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,857] INFO [Broker id=100] Follower monitornotifications-0 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,857] INFO [Broker id=100] Follower __consumer_offsets-25 starts at leader epoch 59 from offset 0 with partition epoch 69 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 59. (state.change.logger)
[2024-04-06 23:54:54,857] INFO [Broker id=100] Follower __consumer_offsets-39 starts at leader epoch 64 from offset 0 with partition epoch 75 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower __consumer_offsets-8 starts at leader epoch 65 from offset 0 with partition epoch 76 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower __consumer_offsets-6 starts at leader epoch 60 from offset 0 with partition epoch 67 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower __consumer_offsets-35 starts at leader epoch 66 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower __consumer_offsets-4 starts at leader epoch 66 from offset 0 with partition epoch 74 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower aggregator.traces-0 starts at leader epoch 68 from offset 0 with partition epoch 72 and high watermark 0. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 68. (state.change.logger)
[2024-04-06 23:54:54,858] INFO [Broker id=100] Follower __consumer_offsets-2 starts at leader epoch 63 from offset 26 with partition epoch 70 and high watermark 26. Current leader is -1. Previous leader Some(-1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:54:54,861] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-38, __consumer_offsets-49, metadata.rollup.compactions-0, __consumer_offsets-16, __consumer_offsets-8, __consumer_offsets-2, __consumer_offsets-13, __consumer_offsets-35, __consumer_offsets-24, monitornotifications-0, ingestion.metrics-0, __consumer_offsets-32, __consumer_offsets-48, __consumer_offsets-29, __consumer_offsets-18, __consumer_offsets-40, __consumer_offsets-7, __consumer_offsets-23, __consumer_offsets-4, __consumer_offsets-26, __consumer_offsets-42, __consumer_offsets-31, metadata.ingest.stats-1, __consumer_offsets-20, __consumer_offsets-12, __consumer_offsets-6, __consumer_offsets-17, __consumer_offsets-39, eval_global_aggregation-0, __consumer_offsets-47, __consumer_offsets-25, __consumer_offsets-3, __consumer_offsets-14, __consumer_offsets-30, __consumer_offsets-41, metadata.ingest.stats-0, ingestion.logs-1, aggregator.traces-0) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:54,861] INFO [Broker id=100] Stopped fetchers as part of become-follower for 38 partitions (state.change.logger)
[2024-04-06 23:54:54,929] INFO [Broker id=100] Started fetchers as part of become-follower for 38 partitions (state.change.logger)
[2024-04-06 23:54:54,939] INFO [ReplicaFetcherThread-0-1]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,939] INFO [ReplicaFetcherThread-0-1]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,939] INFO [ReplicaFetcherThread-0-1]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:54,943] INFO [ReplicaFetcherThread-0-102]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,029] INFO [ReplicaFetcherThread-0-102]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,029] INFO [ReplicaFetcherThread-0-102]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,034] INFO [ReplicaFetcherThread-0-101]: Shutting down (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,035] INFO [ReplicaFetcherThread-0-101]: Stopped (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,035] INFO [ReplicaFetcherThread-0-101]: Shutdown completed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,038] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,038] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[59] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 26 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[59] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,039] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,039] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[59] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 14 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,040] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,040] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,041] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,041] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,041] INFO [GroupCoordinator 100]: Unloading group metadata for metadata.index.appends.consumer with generation 15 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,041] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[59] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 8 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 35 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,042] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,042] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,044] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,044] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[59]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-26 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[59]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[59]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,045] INFO [GroupCoordinator 100]: Unloading group metadata for metadata.ingest.stats.consumer with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,046] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-14 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[59]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-8 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-35 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,047] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,330] INFO [Broker id=100] Transitioning 24 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower __consumer_offsets-48 starts at leader epoch 64 from offset 26 with partition epoch 71 and high watermark 26. Current leader is 101. Previous leader Some(101) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower ingestion.metrics-0 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower __consumer_offsets-13 starts at leader epoch 60 from offset 0 with partition epoch 72 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower eval_global_aggregation-0 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower __consumer_offsets-12 starts at leader epoch 61 from offset 0 with partition epoch 68 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:55,331] INFO [Broker id=100] Follower __consumer_offsets-42 starts at leader epoch 67 from offset 0 with partition epoch 75 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-24 starts at leader epoch 64 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-20 starts at leader epoch 67 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-17 starts at leader epoch 64 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-49 starts at leader epoch 67 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-18 starts at leader epoch 67 from offset 0 with partition epoch 75 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-31 starts at leader epoch 66 from offset 0 with partition epoch 74 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-32 starts at leader epoch 67 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower __consumer_offsets-29 starts at leader epoch 61 from offset 0 with partition epoch 68 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:55,332] INFO [Broker id=100] Follower metadata.ingest.stats-1 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower metadata.rollup.compactions-0 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower monitornotifications-0 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-25 starts at leader epoch 60 from offset 0 with partition epoch 70 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-7 starts at leader epoch 60 from offset 0 with partition epoch 72 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-6 starts at leader epoch 61 from offset 0 with partition epoch 68 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-38 starts at leader epoch 60 from offset 0 with partition epoch 72 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-3 starts at leader epoch 62 from offset 0 with partition epoch 68 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower __consumer_offsets-4 starts at leader epoch 67 from offset 0 with partition epoch 75 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:54:55,333] INFO [Broker id=100] Follower aggregator.traces-0 starts at leader epoch 69 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 101. Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:54:55,334] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-38, __consumer_offsets-49, metadata.rollup.compactions-0, __consumer_offsets-13, __consumer_offsets-24, monitornotifications-0, ingestion.metrics-0, __consumer_offsets-32, __consumer_offsets-48, __consumer_offsets-7, __consumer_offsets-29, __consumer_offsets-18, __consumer_offsets-4, __consumer_offsets-42, metadata.ingest.stats-1, __consumer_offsets-20, __consumer_offsets-31, __consumer_offsets-12, __consumer_offsets-6, __consumer_offsets-17, eval_global_aggregation-0, __consumer_offsets-3, __consumer_offsets-25, aggregator.traces-0) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:55,334] INFO [Broker id=100] Stopped fetchers as part of become-follower for 24 partitions (state.change.logger)
[2024-04-06 23:54:55,340] INFO [ReplicaFetcherThread-0-101]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,342] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 101 for partitions Map(__consumer_offsets-38 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),60,0), __consumer_offsets-49 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), metadata.rollup.compactions-0 -> InitialFetchState(Some(ZFtp0aF4Q52jZYgVwYe6oA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0), __consumer_offsets-13 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),60,0), __consumer_offsets-24 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),64,0), monitornotifications-0 -> InitialFetchState(Some(oMm9lBwLQrGC4CJxe51XcA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0), ingestion.metrics-0 -> InitialFetchState(Some(MJvkOKIfSfitCb-7_9GyQA),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0), __consumer_offsets-32 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), __consumer_offsets-48 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),64,26), __consumer_offsets-7 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),60,0), __consumer_offsets-29 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),61,0), __consumer_offsets-18 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), __consumer_offsets-4 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), __consumer_offsets-42 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), metadata.ingest.stats-1 -> InitialFetchState(Some(Fhj_NBEDS6O3D-rvdfB6rg),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0), __consumer_offsets-20 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), __consumer_offsets-31 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),66,0), __consumer_offsets-12 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),61,0), __consumer_offsets-6 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),61,0), __consumer_offsets-17 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),64,0), eval_global_aggregation-0 -> InitialFetchState(Some(Nn7tXOYpTFe2hXwm9RMy8A),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0), __consumer_offsets-3 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-25 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),60,0), aggregator.traces-0 -> InitialFetchState(Some(N4cRvHiKSA6ycNHWiVYb5A),BrokerEndPoint(id=101, host=kafka-kraft-broker-1.kafka-kraft-broker-headless.default.svc.cluster.local:9094),69,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:55,342] INFO [Broker id=100] Started fetchers as part of become-follower for 24 partitions (state.change.logger)
[2024-04-06 23:54:55,342] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,343] INFO [UnifiedLog partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,343] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-38 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,343] INFO [UnifiedLog partition=__consumer_offsets-38, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,343] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,343] INFO [UnifiedLog partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,343] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-25 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,343] INFO [UnifiedLog partition=__consumer_offsets-25, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,344] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-12 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,344] INFO [UnifiedLog partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,344] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,344] INFO [UnifiedLog partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,344] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-7 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,344] INFO [UnifiedLog partition=__consumer_offsets-7, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,344] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,344] INFO [UnifiedLog partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,344] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-13 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,344] INFO [UnifiedLog partition=__consumer_offsets-13, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,345] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,345] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,346] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,346] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,346] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,346] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,347] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,348] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,429] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,430] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,446] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Truncating partition __consumer_offsets-48 with TruncationState(offset=26, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=48, leaderEpoch=2, endOffset=26) (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:54:55,447] INFO [UnifiedLog partition=__consumer_offsets-48, dir=/bitnami/kafka/data] Truncating to 26 has no effect as the largest offset in the log is 25 (kafka.log.UnifiedLog)
[2024-04-06 23:54:55,831] INFO [Broker id=100] Transitioning 14 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:54:55,831] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-14, __consumer_offsets-41, __consumer_offsets-23, ingestion.logs-1, metadata.ingest.stats-0, __consumer_offsets-30, __consumer_offsets-26, __consumer_offsets-39, __consumer_offsets-40, __consumer_offsets-8, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:55,831] INFO [Broker id=100] Leader __consumer_offsets-47 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 65 from offset 0 with partition epoch 76, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,837] INFO [Broker id=100] Leader __consumer_offsets-16 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 61 from offset 0 with partition epoch 70, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,842] INFO [Broker id=100] Leader __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 66 from offset 26 with partition epoch 77, high watermark 26, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:54:55,847] INFO [Broker id=100] Leader __consumer_offsets-41 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 63 from offset 0 with partition epoch 75, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:54:55,852] INFO [Broker id=100] Leader __consumer_offsets-23 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 65 from offset 0 with partition epoch 76, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,857] INFO [Broker id=100] Leader ingestion.logs-1 with topic id Some(hlx5EftcTMe2-opCgnStUQ) starts at leader epoch 61 from offset 0 with partition epoch 69, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,863] INFO [Broker id=100] Leader metadata.ingest.stats-0 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) starts at leader epoch 61 from offset 0 with partition epoch 69, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,868] INFO [Broker id=100] Leader __consumer_offsets-30 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 62 from offset 0 with partition epoch 72, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 61. (state.change.logger)
[2024-04-06 23:54:55,873] INFO [Broker id=100] Leader __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 67 from offset 0 with partition epoch 77, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:55,878] INFO [Broker id=100] Leader __consumer_offsets-39 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 65 from offset 0 with partition epoch 76, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:54:55,883] INFO [Broker id=100] Leader __consumer_offsets-40 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 61 from offset 0 with partition epoch 70, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 60. (state.change.logger)
[2024-04-06 23:54:55,888] INFO [Broker id=100] Leader __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 66 from offset 0 with partition epoch 77, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:54:55,893] INFO [Broker id=100] Leader __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 67 from offset 0 with partition epoch 73, high watermark 0, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:54:55,898] INFO [Broker id=100] Leader __consumer_offsets-2 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 64 from offset 26 with partition epoch 71, high watermark 26, ISR [100], adding replicas [] and removing replicas [] . Previous leader Some(-1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 47 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 16 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 30 in epoch 62 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 62 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 14 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 41 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 26 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 23 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 39 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 40 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 8 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 35 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,903] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 2 in epoch 64 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,903] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 64 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,904] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-47 in 1 milliseconds for epoch 65, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,904] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds for epoch 61, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,905] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-30 in 2 milliseconds for epoch 62, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,926] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-abcba8f0-f249-47c3-80e0-9d24c8abf48a, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.134, clientHost=/10.43.128.134, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,926] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-5800ec0b-877c-44f0-967d-7c452e136b3c, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.136, clientHost=/10.43.128.136, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,927] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-cc551c06-87dd-4ea0-abf0-4c460030495e, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.137, clientHost=/10.43.128.137, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,927] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-e9a25728-88f8-4313-90d8-0417d1875693, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.139, clientHost=/10.43.128.139, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,927] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-0c986f24-7201-4ce2-a1b2-fcdb1d5f7b23, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,928] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-cd7f4ef7-0a1f-4be1-8257-0a8ec5385a10, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,928] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-3002a1d2-28c5-4903-a81f-a3a69fc17114, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.129.222, clientHost=/10.43.129.222, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 9. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,928] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-49c8271b-62bb-4dc0-b3bb-2ae66c9133c7, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.42, clientHost=/10.43.128.42, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 11. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,929] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-8b4ba1cc-9ea3-412b-8934-f29fb340c794, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.43, clientHost=/10.43.128.43, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 13. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,929] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-e78065b6-0f83-4397-92ae-965997f4b1a2, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.45, clientHost=/10.43.128.45, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 15. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,929] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-e0dc7f14-811b-4fff-a197-1de19e4ae5a8, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.46, clientHost=/10.43.128.46, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 17. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,930] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-db81d438-6b92-4574-9043-24f50fa20124, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.47, clientHost=/10.43.128.47, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 19. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,930] INFO Loaded member MemberMetadata(memberId=metadata.ingest.stats.consumer-0-ae145ec9-744c-4b1c-b2a7-dcc9eba624a8, groupInstanceId=Some(metadata.ingest.stats.consumer-0), clientId=stats_10.43.128.48, clientHost=/10.43.128.48, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.ingest.stats.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,930] INFO [GroupCoordinator 100]: Loading group metadata for metadata.ingest.stats.consumer with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,931] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-14 in 28 milliseconds for epoch 66, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,931] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-41 in 28 milliseconds for epoch 63, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,931] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-26 in 28 milliseconds for epoch 67, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,931] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-23 in 28 milliseconds for epoch 65, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,931] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-39 in 28 milliseconds for epoch 65, of which 28 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,932] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-40 in 29 milliseconds for epoch 61, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,932] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-8 in 29 milliseconds for epoch 66, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,932] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-35 in 29 milliseconds for epoch 67, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:55,953] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-5b1cebd2-aa2f-4391-891c-f04441ed7348, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.134, clientHost=/10.43.128.134, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,953] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-9476d719-0dc8-48ff-bef2-f3cd17f0e7da, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.136, clientHost=/10.43.128.136, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,954] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-6371c410-ec93-4226-8f7d-eaffdc16f1c4, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.137, clientHost=/10.43.128.137, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,955] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-a37e9249-b918-4c3e-b103-28feb73cca70, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.139, clientHost=/10.43.128.139, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,955] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-2f557d25-4fac-4a88-8eee-82cd83b96483, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,955] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-e752ab3b-0867-4eb8-b141-20ac37f92b95, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.129.201, clientHost=/10.43.129.201, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,956] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-f0963aa8-4d1f-41e2-b78c-5edd527c8544, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.129.222, clientHost=/10.43.129.222, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,956] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-b7de9835-70c5-44fa-8f24-79f345717b3b, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.42, clientHost=/10.43.128.42, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 5. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,957] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-fd946bf5-5356-403b-bd6c-2bf966296db6, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.43, clientHost=/10.43.128.43, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 7. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,957] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-6be61b83-2693-4a86-8f74-cb9bd0ca9f09, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.45, clientHost=/10.43.128.45, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 9. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,957] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-7c52a7e9-124a-4973-ac49-ce13644f6f89, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.46, clientHost=/10.43.128.46, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 11. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,958] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-dde2f055-496c-4b6c-ad63-22383efca205, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.47, clientHost=/10.43.128.47, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 13. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,958] INFO Loaded member MemberMetadata(memberId=metadata.compaction.consumer-0-4c2be356-4a48-4ff8-8401-39b00077d31d, groupInstanceId=Some(metadata.compaction.consumer-0), clientId=10.43.128.48, clientHost=/10.43.128.48, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group metadata.compaction.consumer with generation 15. (kafka.coordinator.group.GroupMetadata$)
[2024-04-06 23:54:55,958] INFO [GroupCoordinator 100]: Loading group metadata for metadata.compaction.consumer with generation 15 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:55,958] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-2 in 55 milliseconds for epoch 64, of which 29 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,237] INFO [Broker id=100] Transitioning 1 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:56,238] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-13 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 100], partitionEpoch=73, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:56,238] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,238] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,238] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,313] INFO [Partition __consumer_offsets-8 broker=100] ISR updated to 100,102  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:54:56,330] INFO [Broker id=100] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:54:56,330] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-8) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:56,330] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=-1, leader=100, leaderEpoch=66, isr=[100, 102], partitionEpoch=78, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 66. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,331] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 8 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,331] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,331] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-47 broker=100] ISR updated to 100,102  and version updated to 77 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-14 broker=100] ISR updated to 100,102  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-30 broker=100] ISR updated to 100,102  and version updated to 73 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-41 broker=100] ISR updated to 100,102  and version updated to 76 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-26 broker=100] ISR updated to 100,102  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-23 broker=100] ISR updated to 100,102  and version updated to 77 (kafka.cluster.Partition)
[2024-04-06 23:54:56,508] INFO [Partition __consumer_offsets-39 broker=100] ISR updated to 100,102  and version updated to 77 (kafka.cluster.Partition)
[2024-04-06 23:54:56,534] INFO [Broker id=100] Transitioning 7 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:54:56,534] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-30, __consumer_offsets-41, __consumer_offsets-26, __consumer_offsets-23, __consumer_offsets-39) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:56,535] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-47 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102], partitionEpoch=77, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,535] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=-1, leader=100, leaderEpoch=66, isr=[100, 102], partitionEpoch=78, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 66. Current high watermark 26, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,535] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-30 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=-1, leader=100, leaderEpoch=62, isr=[100, 102], partitionEpoch=73, replicas=[1, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 62. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,536] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-41 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=-1, leader=100, leaderEpoch=63, isr=[100, 102], partitionEpoch=76, replicas=[0, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 63. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,536] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=-1, leader=100, leaderEpoch=67, isr=[100, 102], partitionEpoch=78, replicas=[100, 0, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 67. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,536] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-23 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102], partitionEpoch=77, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,536] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-39 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102], partitionEpoch=77, replicas=[102, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:56,536] INFO [Broker id=100] Transitioning 2 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:56,537] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-48 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100], partitionEpoch=72, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:54:56,537] INFO [Broker id=100] Skipped the become-follower state change for ingestion.metrics-0 with topic id Some(MJvkOKIfSfitCb-7_9GyQA) and partition state LeaderAndIsrPartitionState(topicName='ingestion.metrics', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 47 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 14 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 30 in epoch 62 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 62 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 41 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 26 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 23 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 39 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,537] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,538] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,835] INFO [Broker id=100] Transitioning 22 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-13 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=13, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 100, 102], partitionEpoch=74, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for eval_global_aggregation-0 with topic id Some(Nn7tXOYpTFe2hXwm9RMy8A) and partition state LeaderAndIsrPartitionState(topicName='eval_global_aggregation', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-12 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100], partitionEpoch=69, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-42 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102], partitionEpoch=76, replicas=[100, 102, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-24 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100], partitionEpoch=72, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-20 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100], partitionEpoch=72, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-17 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100], partitionEpoch=72, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-49 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100], partitionEpoch=72, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-18 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102], partitionEpoch=76, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,836] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-31 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=-1, leader=101, leaderEpoch=66, isr=[101, 102], partitionEpoch=75, replicas=[102, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 66. (state.change.logger)
[2024-04-06 23:54:56,837] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100], partitionEpoch=74, replicas=[100, 101, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,837] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-29 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100], partitionEpoch=69, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:56,838] INFO [Broker id=100] Skipped the become-follower state change for metadata.ingest.stats-1 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) and partition state LeaderAndIsrPartitionState(topicName='metadata.ingest.stats', partitionIndex=1, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,838] INFO [Broker id=100] Skipped the become-follower state change for metadata.rollup.compactions-0 with topic id Some(ZFtp0aF4Q52jZYgVwYe6oA) and partition state LeaderAndIsrPartitionState(topicName='metadata.rollup.compactions', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,838] INFO [Broker id=100] Skipped the become-follower state change for monitornotifications-0 with topic id Some(oMm9lBwLQrGC4CJxe51XcA) and partition state LeaderAndIsrPartitionState(topicName='monitornotifications', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,839] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-25 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 100], partitionEpoch=71, replicas=[101, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:56,839] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-7 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 102], partitionEpoch=73, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:56,839] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-38 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 102], partitionEpoch=73, replicas=[101, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:56,839] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-6 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100], partitionEpoch=69, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:56,839] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-3 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=-1, leader=101, leaderEpoch=62, isr=[101, 100], partitionEpoch=69, replicas=[1, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 62. (state.change.logger)
[2024-04-06 23:54:56,840] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-4 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102], partitionEpoch=76, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:56,840] INFO [Broker id=100] Skipped the become-follower state change for aggregator.traces-0 with topic id Some(N4cRvHiKSA6ycNHWiVYb5A) and partition state LeaderAndIsrPartitionState(topicName='aggregator.traces', partitionIndex=0, controllerEpoch=-1, leader=101, leaderEpoch=69, isr=[101, 100], partitionEpoch=74, replicas=[100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 69. (state.change.logger)
[2024-04-06 23:54:56,840] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 13 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-13 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,840] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,840] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,841] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:56,841] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:56,842] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,133] INFO [Broker id=100] Transitioning 1 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:57,134] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-7 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=7, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 102, 100], partitionEpoch=74, replicas=[101, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:57,134] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 7 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,134] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,134] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-7 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,217] INFO [Broker id=100] Transitioning 5 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:57,218] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-31 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=31, controllerEpoch=-1, leader=101, leaderEpoch=66, isr=[101, 102, 100], partitionEpoch=76, replicas=[102, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 66. (state.change.logger)
[2024-04-06 23:54:57,229] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-38 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=38, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 102, 100], partitionEpoch=74, replicas=[101, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:54:57,230] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-4 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=4, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102, 100], partitionEpoch=77, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:57,230] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-42 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=42, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102, 100], partitionEpoch=77, replicas=[100, 102, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:57,231] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-18 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=18, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 102, 100], partitionEpoch=77, replicas=[100, 101, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:57,231] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,231] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,231] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 42 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,231] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,231] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 38 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 4 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 18 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-42 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-38 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-4 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:57,232] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-18 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,137] INFO [Broker id=100] Transitioning 1 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:59,137] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-6 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=6, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100, 1], partitionEpoch=70, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:59,138] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,138] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,138] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,336] INFO [Broker id=100] Transitioning 5 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:54:59,338] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-29 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=29, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100, 1], partitionEpoch=70, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:59,338] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-3 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=3, controllerEpoch=-1, leader=101, leaderEpoch=62, isr=[101, 100, 1], partitionEpoch=70, replicas=[1, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 62. (state.change.logger)
[2024-04-06 23:54:59,338] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-12 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=12, controllerEpoch=-1, leader=101, leaderEpoch=61, isr=[101, 100, 1], partitionEpoch=70, replicas=[1, 101, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 61. (state.change.logger)
[2024-04-06 23:54:59,338] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-20 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=20, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100, 1], partitionEpoch=73, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:59,339] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-49 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=49, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100, 1], partitionEpoch=73, replicas=[100, 101, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:54:59,340] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,340] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,340] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[61] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,340] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,340] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,340] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,340] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 20 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[61]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 49 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-20 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,341] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-49 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,394] INFO [Partition ingestion.logs-1 broker=100] ISR updated to 100,1  and version updated to 70 (kafka.cluster.Partition)
[2024-04-06 23:54:59,429] INFO [Broker id=100] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:54:59,429] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(ingestion.logs-1) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:59,430] INFO [Broker id=100] Skipped the become-leader state change for ingestion.logs-1 with topic id Some(hlx5EftcTMe2-opCgnStUQ) and partition state LeaderAndIsrPartitionState(topicName='ingestion.logs', partitionIndex=1, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1], partitionEpoch=70, replicas=[1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,495] INFO [Partition __consumer_offsets-16 broker=100] ISR updated to 100,1  and version updated to 71 (kafka.cluster.Partition)
[2024-04-06 23:54:59,495] INFO [Partition metadata.ingest.stats-0 broker=100] ISR updated to 100,1  and version updated to 70 (kafka.cluster.Partition)
[2024-04-06 23:54:59,495] INFO [Partition __consumer_offsets-30 broker=100] ISR updated to 100,102,1  and version updated to 74 (kafka.cluster.Partition)
[2024-04-06 23:54:59,496] INFO [Partition __consumer_offsets-40 broker=100] ISR updated to 100,1  and version updated to 71 (kafka.cluster.Partition)
[2024-04-06 23:54:59,496] INFO [Partition __consumer_offsets-35 broker=100] ISR updated to 100,1  and version updated to 74 (kafka.cluster.Partition)
[2024-04-06 23:54:59,496] INFO [Partition __consumer_offsets-2 broker=100] ISR updated to 100,1  and version updated to 72 (kafka.cluster.Partition)
[2024-04-06 23:54:59,836] INFO [Broker id=100] Transitioning 6 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:54:59,837] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-16, __consumer_offsets-40, metadata.ingest.stats-0, __consumer_offsets-30, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:54:59,837] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-16 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1], partitionEpoch=71, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,838] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-40 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1], partitionEpoch=71, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,838] INFO [Broker id=100] Skipped the become-leader state change for metadata.ingest.stats-0 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) and partition state LeaderAndIsrPartitionState(topicName='metadata.ingest.stats', partitionIndex=0, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1], partitionEpoch=70, replicas=[1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,838] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-30 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=30, controllerEpoch=-1, leader=100, leaderEpoch=62, isr=[100, 102, 1], partitionEpoch=74, replicas=[1, 102, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 62. Current high watermark 0, ISR [100,102,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,839] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=-1, leader=100, leaderEpoch=67, isr=[100, 1], partitionEpoch=74, replicas=[100, 0, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 67. Current high watermark 0, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,839] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-2 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=-1, leader=100, leaderEpoch=64, isr=[100, 1], partitionEpoch=72, replicas=[0, 1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 64. Current high watermark 26, ISR [100,1], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:54:59,839] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 16 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,839] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 30 in epoch 62 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 62 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 40 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 35 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 2 in epoch 64 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 64 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,840] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:54:59,841] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,195] INFO [Partition __consumer_offsets-16 broker=100] ISR updated to 100,1,0  and version updated to 72 (kafka.cluster.Partition)
[2024-04-06 23:55:01,224] INFO [Broker id=100] Transitioning 1 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:55:01,224] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-16) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:55:01,225] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-16 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=16, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1, 0], partitionEpoch=72, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,225] INFO [Broker id=100] Transitioning 1 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:55:01,225] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-24 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=24, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100, 0], partitionEpoch=73, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:55:01,225] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 16 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,225] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,225] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,225] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,225] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,225] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,297] INFO [Partition __consumer_offsets-47 broker=100] ISR updated to 100,102,0  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:55:01,297] INFO [Partition __consumer_offsets-14 broker=100] ISR updated to 100,102,0  and version updated to 79 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-41 broker=100] ISR updated to 100,102,0  and version updated to 77 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-26 broker=100] ISR updated to 100,102,0  and version updated to 79 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-23 broker=100] ISR updated to 100,102,0  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-39 broker=100] ISR updated to 100,102,0  and version updated to 78 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-8 broker=100] ISR updated to 100,102,0  and version updated to 79 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-40 broker=100] ISR updated to 100,1,0  and version updated to 72 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-35 broker=100] ISR updated to 100,1,0  and version updated to 75 (kafka.cluster.Partition)
[2024-04-06 23:55:01,298] INFO [Partition __consumer_offsets-2 broker=100] ISR updated to 100,1,0  and version updated to 73 (kafka.cluster.Partition)
[2024-04-06 23:55:01,336] INFO [Broker id=100] Transitioning 10 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:55:01,337] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-47, __consumer_offsets-14, __consumer_offsets-41, __consumer_offsets-26, __consumer_offsets-23, __consumer_offsets-39, __consumer_offsets-8, __consumer_offsets-40, __consumer_offsets-35, __consumer_offsets-2) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:55:01,338] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-47 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=47, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102, 0], partitionEpoch=78, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,338] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-14 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=14, controllerEpoch=-1, leader=100, leaderEpoch=66, isr=[100, 102, 0], partitionEpoch=79, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 66. Current high watermark 26, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,339] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-41 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=41, controllerEpoch=-1, leader=100, leaderEpoch=63, isr=[100, 102, 0], partitionEpoch=77, replicas=[0, 100, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 63. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,339] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-26 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=26, controllerEpoch=-1, leader=100, leaderEpoch=67, isr=[100, 102, 0], partitionEpoch=79, replicas=[100, 0, 102], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 67. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,339] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-23 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=23, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102, 0], partitionEpoch=78, replicas=[102, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,340] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-39 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=39, controllerEpoch=-1, leader=100, leaderEpoch=65, isr=[100, 102, 0], partitionEpoch=78, replicas=[102, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 65. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,341] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-8 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=8, controllerEpoch=-1, leader=100, leaderEpoch=66, isr=[100, 102, 0], partitionEpoch=79, replicas=[100, 102, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 66. Current high watermark 0, ISR [100,102,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,341] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-40 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=40, controllerEpoch=-1, leader=100, leaderEpoch=61, isr=[100, 1, 0], partitionEpoch=72, replicas=[1, 0, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 61. Current high watermark 0, ISR [100,1,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-35 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=35, controllerEpoch=-1, leader=100, leaderEpoch=67, isr=[100, 1, 0], partitionEpoch=75, replicas=[100, 0, 1], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 67. Current high watermark 0, ISR [100,1,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-leader state change for __consumer_offsets-2 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=2, controllerEpoch=-1, leader=100, leaderEpoch=64, isr=[100, 1, 0], partitionEpoch=73, replicas=[0, 1, 100], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already the leader with leader epoch 64. Current high watermark 26, ISR [100,1,0], adding replicas [] and removing replicas []. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Transitioning 4 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=32, controllerEpoch=-1, leader=101, leaderEpoch=67, isr=[101, 100, 0], partitionEpoch=75, replicas=[100, 101, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 67. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-48 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=48, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100, 0], partitionEpoch=73, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-25 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=25, controllerEpoch=-1, leader=101, leaderEpoch=60, isr=[101, 100, 0], partitionEpoch=72, replicas=[101, 100, 0], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 60. (state.change.logger)
[2024-04-06 23:55:01,342] INFO [Broker id=100] Skipped the become-follower state change for __consumer_offsets-17 with topic id Some(bMQvYuPsTuWoGw93TAK53w) and partition state LeaderAndIsrPartitionState(topicName='__consumer_offsets', partitionIndex=17, controllerEpoch=-1, leader=101, leaderEpoch=64, isr=[101, 100, 0], partitionEpoch=73, replicas=[0, 100, 101], addingReplicas=[], removingReplicas=[], isNew=false, leaderRecoveryState=0) since it is already a follower with leader epoch 64. (state.change.logger)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 47 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 14 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 41 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 26 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 23 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 39 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 8 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 40 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,343] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 35 in epoch 67 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 67 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 2 in epoch 64 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 64 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Already loading offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 32 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-32 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 25 in epoch OptionalInt[60] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-25 for coordinator epoch OptionalInt[60]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:55:01,344] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:32,886] INFO [Broker id=100] Transitioning 12 partition(s) to local leaders. (state.change.logger)
[2024-04-06 23:57:32,888] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-32, ingestion.metrics-0, metadata.ingest.stats-1, metadata.rollup.compactions-0, eval_global_aggregation-0, monitornotifications-0, __consumer_offsets-42, __consumer_offsets-4, __consumer_offsets-20, aggregator.traces-0, __consumer_offsets-49, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:57:32,888] INFO [Broker id=100] Leader __consumer_offsets-32 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 76, high watermark 0, ISR [101,100,0], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,894] INFO [Broker id=100] Leader ingestion.metrics-0 with topic id Some(MJvkOKIfSfitCb-7_9GyQA) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,899] INFO [Broker id=100] Leader metadata.ingest.stats-1 with topic id Some(Fhj_NBEDS6O3D-rvdfB6rg) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,904] INFO [Broker id=100] Leader metadata.rollup.compactions-0 with topic id Some(ZFtp0aF4Q52jZYgVwYe6oA) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,909] INFO [Broker id=100] Leader eval_global_aggregation-0 with topic id Some(Nn7tXOYpTFe2hXwm9RMy8A) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,914] INFO [Broker id=100] Leader monitornotifications-0 with topic id Some(oMm9lBwLQrGC4CJxe51XcA) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,919] INFO [Broker id=100] Leader __consumer_offsets-42 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 78, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,923] INFO [Broker id=100] Leader __consumer_offsets-4 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 78, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,934] INFO [Broker id=100] Leader __consumer_offsets-20 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 74, high watermark 0, ISR [101,100,1], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,938] INFO [Broker id=100] Leader aggregator.traces-0 with topic id Some(N4cRvHiKSA6ycNHWiVYb5A) starts at leader epoch 70 from offset 0 with partition epoch 75, high watermark 0, ISR [101,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 69. (state.change.logger)
[2024-04-06 23:57:32,943] INFO [Broker id=100] Leader __consumer_offsets-49 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 74, high watermark 0, ISR [101,100,1], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,947] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-48 has an older epoch (64) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,947] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-48 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,947] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-17 has an older epoch (64) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,948] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-17 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,948] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-6 has an older epoch (61) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,948] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-6 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,948] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-3 has an older epoch (62) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,948] INFO [Broker id=100] Leader __consumer_offsets-18 with topic id Some(bMQvYuPsTuWoGw93TAK53w) starts at leader epoch 68 from offset 0 with partition epoch 78, high watermark 0, ISR [101,102,100], adding replicas [] and removing replicas [] . Previous leader Some(101) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,948] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-3 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-29 has an older epoch (61) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-29 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-12 has an older epoch (61) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-12 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-31 has an older epoch (66) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-31 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,949] INFO [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-24 has an older epoch (64) than the current leader. Will await the new LeaderAndIsr state before resuming fetching. (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,950] WARN [ReplicaFetcher replicaId=100, leaderId=101, fetcherId=0] Partition __consumer_offsets-24 marked as failed (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:32,954] INFO [Broker id=100] Transitioning 18 partition(s) to local followers. (state.change.logger)
[2024-04-06 23:57:32,954] INFO [Broker id=100] Follower __consumer_offsets-47 starts at leader epoch 66 from offset 0 with partition epoch 79 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:57:32,954] INFO [Broker id=100] Follower __consumer_offsets-16 starts at leader epoch 62 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower __consumer_offsets-48 starts at leader epoch 65 from offset 26 with partition epoch 74 and high watermark 26. Current leader is 0. Previous leader Some(0) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower __consumer_offsets-12 starts at leader epoch 62 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower __consumer_offsets-41 starts at leader epoch 64 from offset 0 with partition epoch 78 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 64. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower __consumer_offsets-23 starts at leader epoch 66 from offset 0 with partition epoch 79 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower __consumer_offsets-24 starts at leader epoch 65 from offset 0 with partition epoch 74 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:57:32,955] INFO [Broker id=100] Follower ingestion.logs-1 starts at leader epoch 62 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,956] INFO [Broker id=100] Follower __consumer_offsets-17 starts at leader epoch 65 from offset 0 with partition epoch 74 and high watermark 0. Current leader is 0. Previous leader Some(0) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:57:32,956] INFO [Broker id=100] Follower __consumer_offsets-31 starts at leader epoch 67 from offset 0 with partition epoch 77 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 67. (state.change.logger)
[2024-04-06 23:57:32,956] INFO [Broker id=100] Follower metadata.ingest.stats-0 starts at leader epoch 62 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,956] INFO [Broker id=100] Follower __consumer_offsets-29 starts at leader epoch 62 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,956] INFO [Broker id=100] Follower __consumer_offsets-30 starts at leader epoch 63 from offset 0 with partition epoch 75 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:57:32,957] INFO [Broker id=100] Follower __consumer_offsets-39 starts at leader epoch 66 from offset 0 with partition epoch 79 and high watermark 0. Current leader is 102. Previous leader Some(102) and previous leader epoch was 66. (state.change.logger)
[2024-04-06 23:57:32,957] INFO [Broker id=100] Follower __consumer_offsets-40 starts at leader epoch 62 from offset 0 with partition epoch 73 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,957] INFO [Broker id=100] Follower __consumer_offsets-6 starts at leader epoch 62 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 62. (state.change.logger)
[2024-04-06 23:57:32,957] INFO [Broker id=100] Follower __consumer_offsets-3 starts at leader epoch 63 from offset 0 with partition epoch 71 and high watermark 0. Current leader is 1. Previous leader Some(1) and previous leader epoch was 63. (state.change.logger)
[2024-04-06 23:57:32,957] INFO [Broker id=100] Follower __consumer_offsets-2 starts at leader epoch 65 from offset 26 with partition epoch 74 and high watermark 26. Current leader is 0. Previous leader Some(0) and previous leader epoch was 65. (state.change.logger)
[2024-04-06 23:57:32,958] INFO [ReplicaFetcherManager on broker 100] Removed fetcher for partitions Set(__consumer_offsets-16, __consumer_offsets-2, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-40, __consumer_offsets-29, __consumer_offsets-23, __consumer_offsets-31, __consumer_offsets-12, __consumer_offsets-6, __consumer_offsets-39, __consumer_offsets-17, __consumer_offsets-47, __consumer_offsets-3, __consumer_offsets-41, metadata.ingest.stats-0, __consumer_offsets-30, ingestion.logs-1) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:57:32,958] INFO [Broker id=100] Stopped fetchers as part of become-follower for 18 partitions (state.change.logger)
[2024-04-06 23:57:33,030] INFO [ReplicaFetcherThread-0-1]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,031] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 1 for partitions Map(__consumer_offsets-16 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-29 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-40 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-12 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-6 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-3 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),63,0), ingestion.logs-1 -> InitialFetchState(Some(hlx5EftcTMe2-opCgnStUQ),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), metadata.ingest.stats-0 -> InitialFetchState(Some(Fhj_NBEDS6O3D-rvdfB6rg),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),62,0), __consumer_offsets-30 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=1, host=kafka-kraft-controller-1.kafka-kraft-controller-headless.default.svc.cluster.local:9094),63,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:57:33,031] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-6 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,031] INFO [UnifiedLog partition=__consumer_offsets-6, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:57:33,032] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,032] INFO [UnifiedLog partition=__consumer_offsets-3, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:57:33,032] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-12 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,032] INFO [UnifiedLog partition=__consumer_offsets-12, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:57:33,032] INFO [ReplicaFetcher replicaId=100, leaderId=1, fetcherId=0] Truncating partition __consumer_offsets-29 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,032] INFO [UnifiedLog partition=__consumer_offsets-29, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:57:33,035] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 0 for partitions Map(__consumer_offsets-24 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),65,0), __consumer_offsets-2 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),65,26), __consumer_offsets-48 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),65,26), __consumer_offsets-17 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),65,0), __consumer_offsets-41 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=0, host=kafka-kraft-controller-0.kafka-kraft-controller-headless.default.svc.cluster.local:9094),64,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:57:33,035] INFO [ReplicaFetcherThread-0-0]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,039] INFO [ReplicaFetcherThread-0-102]: Starting (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,039] INFO [ReplicaFetcherManager on broker 100] Added fetcher to broker 102 for partitions Map(__consumer_offsets-23 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),66,0), __consumer_offsets-31 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),67,0), __consumer_offsets-39 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),66,0), __consumer_offsets-47 -> InitialFetchState(Some(bMQvYuPsTuWoGw93TAK53w),BrokerEndPoint(id=102, host=kafka-kraft-broker-2.kafka-kraft-broker-headless.default.svc.cluster.local:9094),66,0)) (kafka.server.ReplicaFetcherManager)
[2024-04-06 23:57:33,039] INFO [Broker id=100] Started fetchers as part of become-follower for 18 partitions (state.change.logger)
[2024-04-06 23:57:33,039] INFO [ReplicaFetcher replicaId=100, leaderId=102, fetcherId=0] Truncating partition __consumer_offsets-31 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:33,039] INFO [UnifiedLog partition=__consumer_offsets-31, dir=/bitnami/kafka/data] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2024-04-06 23:57:33,041] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 32 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,042] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,042] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 42 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,042] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,042] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 4 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,042] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,042] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 20 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,042] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,042] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 49 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,043] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,043] INFO [GroupCoordinator 100]: Elected as the group coordinator for partition 18 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,042] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds for epoch 68, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,043] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds for epoch 68, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,043] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds for epoch 68, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-20 in 2 milliseconds for epoch 68, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds for epoch 68, of which 1 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 47 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 16 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 48 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 12 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 41 in epoch OptionalInt[64] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 23 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 24 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 17 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,045] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,045] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 31 in epoch OptionalInt[67] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 29 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 30 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 39 in epoch OptionalInt[66] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 40 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 6 in epoch OptionalInt[62] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 3 in epoch OptionalInt[63] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,046] INFO [GroupCoordinator 100]: Resigned as the group coordinator for partition 2 in epoch OptionalInt[65] (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,046] INFO [GroupMetadataManager brokerId=100] Scheduling unloading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,044] INFO [GroupMetadataManager brokerId=100] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds for epoch 68, of which 0 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,129] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-47 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-16 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-48 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-12 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-41 for coordinator epoch OptionalInt[64]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-23 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-24 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-17 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-31 for coordinator epoch OptionalInt[67]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-29 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-30 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-39 for coordinator epoch OptionalInt[66]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-40 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-6 for coordinator epoch OptionalInt[62]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-3 for coordinator epoch OptionalInt[63]. Removed 0 cached offsets and 0 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:33,130] INFO [GroupCoordinator 100]: Unloading group metadata for metadata.compaction.consumer with generation 15 (kafka.coordinator.group.GroupCoordinator)
[2024-04-06 23:57:33,131] INFO [GroupMetadataManager brokerId=100] Finished unloading __consumer_offsets-2 for coordinator epoch OptionalInt[65]. Removed 0 cached offsets and 1 cached groups. (kafka.coordinator.group.GroupMetadataManager)
[2024-04-06 23:57:34,145] INFO [ReplicaFetcher replicaId=100, leaderId=0, fetcherId=0] Truncating partition __consumer_offsets-2 with TruncationState(offset=26, completed=true) due to leader epoch and offset EpochEndOffset(errorCode=0, partition=2, leaderEpoch=2, endOffset=26) (kafka.server.ReplicaFetcherThread)
[2024-04-06 23:57:34,145] INFO [UnifiedLog partition=__consumer_offsets-2, dir=/bitnami/kafka/data] Truncating to 26 has no effect as the largest offset in the log is 25 (kafka.log.UnifiedLog)
[2024-04-06 23:58:19,902] INFO [SnapshotGenerator id=100] Creating new KRaft snapshot file snapshot 00000000000000363930-0000000012 because we have waited at least 60 minute(s). (org.apache.kafka.image.publisher.SnapshotGenerator)
[2024-04-06 23:58:19,910] INFO [SnapshotEmitter id=100] Successfully wrote snapshot 00000000000000363930-0000000012 (org.apache.kafka.image.publisher.SnapshotEmitter)
[2024-04-07 00:05:01,576] INFO [BrokerToControllerChannelManager id=100 name=alter-partition] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
